{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "33ed4f28-de4e-4ae5-ada6-751e02e2f407",
   "metadata": {},
   "source": [
    "# Calculate GMSL from FAIR draws using SESL for SSP-RCPs and then map to RFF-SPs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e956919-b9f6-4db9-afd4-e2a832fbf497",
   "metadata": {},
   "source": [
    "This notebook applies the SESL model to estimate the GMSL impact of a pulse, using the 10,000-draw RFF emissions ensemble. The \"baseline\" GMSL value for each draw is calculated from a weighted average of the RCP-based FACTS-derived GMSL estimates used in AR6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f502664b-6e28-4308-9653-84d8dceb38af",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3effac15-5964-497b-a509-b135b3d82ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pickle\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "import pathlib\n",
    "from typing import Sequence, Union\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def fuse_to_gcsmap(path, fs=\"\"):\n",
    "    pass\n",
    "\n",
    "settings_dict = dict(\n",
    "    #############\n",
    "    ## GENERAL\n",
    "    #############\n",
    "    # code metadata\n",
    "    _PACKAGE_DIR=Path(\"./coastal_gmsl_inputs/other\").parent,\n",
    "    FS = \"\",\n",
    "    # unit of analysis for damage regression/projection\n",
    "    HIST_GEOG=\"state\",\n",
    "    PROJ_GEOG=\"cbsa\",\n",
    "    #############\n",
    "    ## HAZARD\n",
    "    #############\n",
    "    # tracks\n",
    "    GEOG=\"conus\",\n",
    "    HIST_TRACK_VERS=\"20210610\",\n",
    "    HIST_TRACK_NAME=\"ibtracs\",\n",
    "    IBTRACS_URL=(\n",
    "        \"https://www.ncei.noaa.gov/data/\"\n",
    "        \"international-best-track-archive-for-climate-stewardship-ibtracs/v04r00/\"\n",
    "        \"access/netcdf/\"\n",
    "    ),\n",
    "    # synthetic track config\n",
    "    SYNTH_TRACK_NAME=\"emanuel\",\n",
    "    SYNTH_TRACK_VERS=\"20220125\",\n",
    "    SYNTH_TRACK_VERS_HIGH=\"20220125_HT\",\n",
    "    SYNTH_REFERENCE_PERIOD=[2000, 2020],\n",
    "    SYNTH_REFERENCE_SCENS=[\"reanal\", \"20th\", \"ssp245\"],\n",
    "    EMANUEL_RADIUS_RESAMPLE_SEED_INDEX=range(3),\n",
    "    HAZARD_TRACKS_SYNTH_PROCESSING_VERS=\"v0.1\",\n",
    "    TRACKRADIUSMODEL_VERS=\"v0.1\",\n",
    "    # projection  ### TODO: UPDATE\n",
    "    GCM_MODELS=[\"ccsm4\", \"ipsl5\", \"hadgem5\", \"mpi5\", \"mri5\", \"miroc5\", \"gfdl5\"],\n",
    "    GCM_SCENARIOS=[\"rcp45\", \"rcp85\"],\n",
    "    GCM_PERIODS=[\"2008_2025\", \"2030_2040\", \"2045_2055\", \"2070_2080\", \"2085_2095\"],\n",
    "    GCM_BASE=\"2008_2025\",\n",
    "    GCM_NRUNS=100,\n",
    "    # reanalysis  ### TODO: UPDATE\n",
    "    REANAL_MODELS=[\"ncep\"],\n",
    "    REANAL_PERIODS=[\"1979_1989\", \"2008_2018\"],\n",
    "    REANAL_SCENARIOS=[\"reanal\"],\n",
    "    REANAL_BASE=\"2008_2018\",\n",
    "    REANAL_NRUNS=200,\n",
    "    # surge\n",
    "    HAZARD_SURGE_VERS=\"20220718\",\n",
    "    SURGE_MODEL_NAME=\"geoclaw\",\n",
    "    HEIGHT_REL_MAX_WTR_VERS=\"v0.1\",\n",
    "    CL_GAUGE_VERS=\"v0.3\",\n",
    "    # wind  ### TODO: UPDATE\n",
    "    HAZARD_WIND_VERS=\"v0.5\",\n",
    "    WIND_MODEL_NAME=\"licrice\",\n",
    "    # SLR\n",
    "    SLR_SYNTH_DATA_VERS=\"20210809\",\n",
    "    SLR_HIST_DATA_VERS=\"REPLACE_WITH_ACTUAL_VALUE_WHEN_USING_HIST_DATA\",\n",
    "    SLR_SSP_INTERPOLATION_VERS=\"v0.1\",\n",
    "    NOAA_TIDE_HARMONICS_VERS=\"20220715\",\n",
    "    #############\n",
    "    ## ELEVATION\n",
    "    #############\n",
    "    DEM_CATALOGUE_VERS=\"20210420\",\n",
    "    SRTM15PLUS_VERS=\"V2.4\",\n",
    "    DATUM_CONVERSION_VERS=\"v0.2\",\n",
    "    #############\n",
    "    ## EXPOSURE\n",
    "    #############\n",
    "    EXPOSURE_BINNED_VERS=\"20220524\",\n",
    "    MAX_HEIGHT_FOR_SURGE=20,  # meters\n",
    "    EXPOSURE_BIN_WIDTH_H=0.1,\n",
    "    EXPOSURE_BIN_WIDTH_V=0.1,\n",
    "    PROTECTED_LOCATIONS_VERS=\"v0.1\",\n",
    "    #############\n",
    "    ## DAMAGE\n",
    "    #############\n",
    "    DAMAGE_VERS=\"v0.2\",\n",
    "    #############\n",
    "    ## DOSERESPONSE\n",
    "    #############\n",
    "    DOSERESPONSE_VERS=\"experiments/br2-experiment-us\",\n",
    "    DOSERESPONSE_NFOLDS=5,\n",
    "    #############\n",
    "    # MC SAMPLING\n",
    "    #############\n",
    "    MC_NSAMPLES=100,\n",
    "    SAMPLING_VERS=\"v0.2\",\n",
    "    #############\n",
    "    ## DOSE\n",
    "    #############\n",
    "    DOSE_VERS=\"v0.1\",\n",
    "    DOSE_MAXS_BIN_EDGES=np.arange(0, 105, 1),\n",
    "    #############\n",
    "    ## GEOGRAPHY\n",
    "    #############\n",
    "    GLOBAL_PROTECTED_AREAS_VERS=\"v2.0\",\n",
    ")\n",
    "############################################################################\n",
    "\n",
    "##############\n",
    "## SETTINGS CLASS\n",
    "##############\n",
    "\n",
    "\n",
    "class pyTCSettings():\n",
    "    \"\"\"\n",
    "    Private settings class used by tests - meant to be inherrited by Settings\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "\n",
    "        # get all default parameters listed above\n",
    "        for k, v in settings_dict.items():\n",
    "            setattr(self, k, kwargs.pop(k, v))\n",
    "        # also set extra kwargs\n",
    "        for k, v in kwargs.items():\n",
    "            setattr(self, k, v)\n",
    "\n",
    "        self.PARAMS = {}\n",
    "\n",
    "\n",
    "    @classmethod\n",
    "    def from_file(cls, filepath=\"pytc_settings.json\", **kwargs):\n",
    "        with open(filepath, \"r\") as f:\n",
    "            file_settings = json.load(f)\n",
    "        file_settings.update(kwargs)\n",
    "\n",
    "        return cls(**file_settings)\n",
    "\n",
    "    @classmethod\n",
    "    def from_pickle(cls, filepath):\n",
    "        with open(filepath, \"rb\") as f:\n",
    "            this_settings = pickle.load(f)\n",
    "\n",
    "        return this_settings\n",
    "\n",
    "    def write_pickle(self, outpath, overwrite=False):\n",
    "        outpath = Path(outpath)\n",
    "        if (not overwrite) and outpath.is_file():\n",
    "            raise ValueError(\n",
    "                \"The file you are trying to write exists and you have not specified \"\n",
    "                f\"overwrite=True. Please set overwrite to False or remove {outpath}\"\n",
    "            )\n",
    "        with open(outpath, \"wb\") as f:\n",
    "            pickle.dump(self, f, protocol=4)\n",
    "\n",
    "    def write(\n",
    "        self,\n",
    "        outdir: Union[str, Path],\n",
    "        kinds: Sequence = [\"pickle\"],\n",
    "        overwrite: bool = False,\n",
    "    ):\n",
    "        \"\"\"Write the contents of this settings object out to settings.[filetype] for\n",
    "        a user-defined set of filetypes, in directory ``outdir``. This is designed to be\n",
    "        called whenever intermediate data is being written out, so that a record of the\n",
    "        settings used to produce that data is preserved.\n",
    "\n",
    "        TODO: Add more precise/readable/stable ways to store settings data, rather than\n",
    "        dumping the entire thing to a pickle file\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        outdir : str or :class:`pathlib.Path`\n",
    "            Directory in which to write `settings.[filetype]` files\n",
    "        kinds : Sequence of str\n",
    "            The kind of files to write. Currently, only 'pickle' is allowed, in which\n",
    "            the entire Settings object is dumped to pickle\n",
    "        overwrite : bool\n",
    "            Whether to overwrite or raise errors if the file you try to write already\n",
    "            exists.\n",
    "\n",
    "        Raises\n",
    "        ------\n",
    "        ValueError\n",
    "            If overwrite=False and a file you are trying to write already exists.\n",
    "        \"\"\"\n",
    "        outdir = Path(outdir)\n",
    "        for k in kinds:\n",
    "            outpath = outdir / f\"settings.{k}\"\n",
    "            write_func = getattr(self, f\"write_{k}\")\n",
    "            write_func(outpath, overwrite=overwrite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ba096a4d-062c-4406-8f1a-2504eab92264",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "# place variables from the global settings file that you'd like to override in\n",
    "# `pytc_settings`\n",
    "pytc_settings = dict(\n",
    "    GEOG=\"global\",\n",
    "    REANAL_MODELS=[\"era5\", \"ncep2\"],\n",
    "    REANAL_PERIODS=[\"1979_2019\"],\n",
    "    REANAL_SCENARIOS=[\"reanal\"],\n",
    "    GCM_MODELS=[\n",
    "        \"ccsm4\",\n",
    "        \"ecearth\",\n",
    "        \"gfdl5\",\n",
    "        \"hadgem5\",\n",
    "        \"ipsl5\",\n",
    "        \"miroc5\",\n",
    "        \"mpi5\",\n",
    "        \"mri5\",\n",
    "    ],\n",
    "    GCM_SCENARIOS=[\"20th\", \"rcp45\", \"rcp85\"],\n",
    "    GCM_PERIODS=[\"1999_2005\", \"2006_2030\", \"2079_2099\"],\n",
    "    SYNTH_REFERENCE_PERIOD=[1999, 2019],\n",
    "    EMANUEL_RADIUS_RESAMPLE_SEED_INDEX=range(10),\n",
    "    SAMPLING_VERS=\"v0.4\",\n",
    "    DOSE_VERS=\"v0.1\",\n",
    "    EXPOSURE_BINNED_VERS=\"v0.14\",\n",
    "    MC_NSAMPLES=1000,\n",
    ")\n",
    "\n",
    "# now define new variables that are specific to glo-co and might not exist in pyTC.\n",
    "# -- Define glo-co related data and model Versions\n",
    "# -- Define glo-o specific objects\n",
    "\n",
    "gloco_settings = dict(\n",
    "    ##############\n",
    "    # MISC\n",
    "    ##############\n",
    "    GLOCO_PACKAGE_DIR=pathlib.Path().absolute() / \"coastal_gmsl_inputs/other/\", # \"./input/\n",
    "    FAIR_SCENARIOS=[\"ssp245\", \"ssp460\", \"ssp370\"],\n",
    "    CIL_COLORS_3=[\"#3393b0\", \"#ff8c00\", \"#ff6553\"],\n",
    "    CIL_COLORS_ALT_3=[\"#3393b0\", \"#ff8c00\", \"#880808\"],\n",
    "    COASTAL_COLORS_3=[\"#3393b0\", \"#a52a2a\", \"#696969\"],\n",
    "    GENERIC_COLORS_5=[\"#d7191c\", \"#fdae61\", \"black\", \"#abd9e9\", \"#2c7bb6\"],\n",
    "    INTEG_BOTTOM_CODING_GDPPC=234.235646874999,\n",
    "    INTEG_ETA=2,\n",
    "    ISO_DROP_NO_SOCIOECON=[\"ATA\", \"CA-\", \"SP-\"],\n",
    "    ISO_TERR_TO_CTRY_MAPPER={\n",
    "        \"ALA\": \"FIN\",\n",
    "        \"BES\": \"NLD\",\n",
    "        \"BVT\": \"NOR\",\n",
    "        \"IOT\": \"GBR\",\n",
    "        \"CXR\": \"AUS\",\n",
    "        \"CL-\": \"FRA\",\n",
    "        \"CCK\": \"AUS\",\n",
    "        \"ATF\": \"FRA\",\n",
    "        \"HMD\": \"AUS\",\n",
    "        \"PCN\": \"GBR\",\n",
    "        \"SGS\": \"GBR\",\n",
    "        \"SJM\": \"NOR\",\n",
    "        \"TKL\": \"NZL\",\n",
    "        \"UMI\": \"USA\",\n",
    "        \"KO-\": \"SRB\",\n",
    "        \"VAT\": \"ITA\",\n",
    "    },\n",
    "    PPP_BASELINE_YEAR=2019,\n",
    "    ##############\n",
    "    # SAMPLING\n",
    "    ##############\n",
    "    BASINS=[\"AL\", \"SI\", \"SP\", \"IO\", \"WP\", \"EP\"],\n",
    "    INTENSITY_THRESHOLDS=[\"low\", \"high\"],\n",
    "    N_BATCHES=500,  # how many \"batches\" to create when binning SLR draws by GMSL\n",
    "    # how many batches to use in final results (subsampling from N_BATCHES)\n",
    "    CLIP_BATCHES=15,\n",
    "    ##############\n",
    "    # PROJECTION\n",
    "    ##############\n",
    "    PROJ_YEAR_RANGE=[2018, 2099],\n",
    "    ##############\n",
    "    # DOSE RESPONSE\n",
    "    ##############\n",
    "    DOSERESPONSE_ALPHAS=np.concatenate([[0], np.logspace(-15, -5, 11, base=10)]),\n",
    "    # DOSERESPONSE_ALPHAS=[0, 1e-5],\n",
    "    DOSERESPONSE_TWEEDIE_POWER=np.arange(1, 3.1, 0.25),\n",
    "    # DOSERESPONSE_TWEEDIE_POWER=[1, 1.5],\n",
    "    DOSERESPONSE_PARAM_GRID_ALL={\n",
    "        \"only_observed\": [\n",
    "            False,\n",
    "            True,\n",
    "        ],  # whether to only include storms that were fully observed over land\n",
    "        \"cutoff_year\": [1950, 1980, 2001],  # when to cut off regression dataset\n",
    "        \"covariates\": [\n",
    "            [],\n",
    "            [\"gdppc_r\"],\n",
    "            [\"lr_wind\"],\n",
    "            [\"gdppc_r\", \"lr_wind\"],\n",
    "        ],  # which covariates to use\n",
    "        \"normalization\": [None, \"treated\", \"total\"],\n",
    "    },\n",
    "    DOSERESPONSE_PARAM_GRID_POLY={\n",
    "        \"power\": [False, True],  # Power or polynomial\n",
    "        \"maxs\": range(15),\n",
    "        \"pddi\": [False, \"linear\"],\n",
    "    },\n",
    "    DOSERESPONSE_PARAM_GRID_BINNED={\"maxs\": [1, 2], \"pddi\": [False, \"linear\"]},\n",
    "    # DOSERESPONSE_PARAM_GRID_BINNED={\"maxs\": [1, 2], \"pddi\": [False]},\n",
    "    ##############\n",
    "    # VERSIONS\n",
    "    ##############\n",
    "    SYNTH_TRACK_VERS=\"20201118\",\n",
    "    SYNTH_TRACK_VERS_HIGH=\"20201217\",\n",
    "    DIVA_VERS=\"20200630\",\n",
    "    DIVASEGSLR_VERS=\"v0.1\",\n",
    "    LITPOP_DOWNLOAD_VERS=\"20200714\",\n",
    "    LITPOP_VERS=\"v0.5\",\n",
    "    EMDAT_DOWNLOAD_VERS=\"20210421\",\n",
    "    EMDAT_VERS=\"v0.2\",\n",
    "    PWT_DOWNLOAD_VERS=\"20210505\",\n",
    "    PWT_VERS=\"v4.0\",\n",
    "    ISIMIP_DOWNLOAD_VERS=\"20210505\",\n",
    "    IIASA_INT_VERS=\"v4.0\",\n",
    "    CIA_DOWNLOAD_VERS=\"20201215\",\n",
    "    GDP_POP_GDPPC_K_VERS=\"v0.7\",\n",
    "    GEG15_VERS=\"v0.1\",\n",
    "    CIAM_VERS=\"v6.6.0\",\n",
    "    IR_VERS=\"v0.1\",\n",
    "    FAIR_RCP_VERS=\"v4.0_Jan212022\",\n",
    "    FAIR_RFF_CO2_VERS=\"v5.03_Feb072022\",\n",
    "    FAIR_RFF_CH4_VERS=\"v5.03_Feb072022\",\n",
    "    FAIR_RFF_N20_VERS=\"v5.03_Feb072022\",\n",
    "    FAIR_RFF_OUT_VERS=\"v5.03_Feb072022\",\n",
    "    FAIR_RFF_CO2_MEDIAN_VERS=\"v5.01_Jan72022\",\n",
    "    SESL_VERS=\"v0.1\",\n",
    "    DAMAGE_PROJ_VERS=\"v0.20\",\n",
    "    AR6_GMSL_VERS=\"v1.0\",\n",
    "    SLR_BINNED_VERS=\"v1.6.0\",\n",
    "\n",
    ")\n",
    "\n",
    "\n",
    "def Settings(**kwargs):\n",
    "\n",
    "    base_settings = pytc_settings.copy()\n",
    "    base_settings.update(kwargs)\n",
    "    out = pyTCSettings(**base_settings)\n",
    "\n",
    "    # get all default parameters listed above\n",
    "    for k, v in {**gloco_settings}.items():\n",
    "        setattr(out, k, kwargs.pop(k, v))\n",
    "\n",
    "    #######################################################################\n",
    "    # Define glo-co specific paths/directories\n",
    "    #######################################################################\n",
    "    ##############\n",
    "    # MISC\n",
    "    ##############\n",
    "    out.DIR_PARAMS_GLOCO = Path(\n",
    "        kwargs.pop(\"DIR_PARAMS_GLOCO\", out.GLOCO_PACKAGE_DIR / \"params\")\n",
    "    )\n",
    "\n",
    "\n",
    "    ################\n",
    "    # HAZARD\n",
    "    ################\n",
    "\n",
    "    \n",
    "    out.DIR_LOCAL = Path('./coastal_gmsl_inputs')#Path(\"./input/\")\n",
    "\n",
    "    out.PATH_HAZARD_SLR_GMSL_RAW_HIST = Path(\n",
    "        kwargs.pop(\n",
    "            \"PATH_HAZARD_SLR_GMSL_RAW_HIST\",\n",
    "            out.DIR_LOCAL / \"other/dangendorf_2019_GMSL_hist.txt\",\n",
    "        )\n",
    "    )\n",
    "    out.PATH_HAZARD_SLR_GMSL_BASELINE_INT_SYNTH = Path(\n",
    "        kwargs.pop(\n",
    "            \"PATH_HAZARD_SLR_GMSL_BASELINE_INT_SYNTH\",\n",
    "            out.DIR_LOCAL / \"other/v1.0.zarr/\"\n",
    "        )\n",
    "    )\n",
    "    out.DIR_HAZARD_FAIR_RFF = Path(\n",
    "        kwargs.pop(\n",
    "            \"DIR_HAZARD_FAIR_RFF\",\n",
    "            out.DIR_LOCAL ,\n",
    "        )\n",
    "    )\n",
    "    out.PATH_HAZARD_GMST_FAIR_RCP = Path(\n",
    "        kwargs.pop(\n",
    "            \"PATH_HAZARD_GMST_FAIR_RCP\",\n",
    "            out.DIR_LOCAL / \"other/ar6_fair162_control_pulse_2020-2030-2040-2050-2060-2070-2080_emis_conc_rf_temp_lambdaeff_emissions-driven_naturalfix_v4.0_Jan212022.nc\",\n",
    "        )\n",
    "    )\n",
    "    out.PATH_HAZARD_GMST_FAIR_RCP_MEDIAN = Path(\n",
    "        kwargs.pop(\n",
    "            \"PATH_HAZARD_GMST_FAIR_RCP_MEDIAN\",\n",
    "            (\n",
    "            out.DIR_LOCAL / \"other/ar6_fair162_medianparams_control_pulse_2020-2080_10yrincrements_conc_rf_temp_lambdaeff_emissions-driven_2naturalfix_v4.0_Jan212022.nc\"\n",
    "            ),\n",
    "        )\n",
    "    )\n",
    "    out.PATH_HAZARD_SLR_GMSL_FAIR_RFF = Path(\n",
    "        kwargs.pop(\n",
    "            \"PATH_HAZARD_SLR_GMSL_FAIR_RFF\",\n",
    "            (\n",
    "                f\"/shares/gcp/integration/rff2/climate/ar6_rff_iter0-19_fair162_control_pulse_2020-2030-2040-2050-2060-2070-2080_gmsl_emissions-driven_naturalfix_{out.FAIR_RFF_OUT_VERS}.zarr\"\n",
    "            ),\n",
    "        )\n",
    "    )\n",
    "    out.DIR_HAZARD_SLR_SESL_RAW = Path(\n",
    "        kwargs.pop(\"DIR_HAZARD_SLR_SESL_RAW\", out.DIR_LOCAL / \"other\")\n",
    "    )\n",
    "\n",
    "    ################\n",
    "    # PARAMS\n",
    "    ################\n",
    "    out.DIR_GLOCO_PARAMS = kwargs.pop(\n",
    "        \"DIR_GLOCO_PARAMS\", out.GLOCO_PACKAGE_DIR / \"params\"\n",
    "    )\n",
    "    with open(out.DIR_GLOCO_PARAMS / \"sesl\" / (out.SESL_VERS + \".json\"), \"r\") as f:\n",
    "        out.PARAMS[\"sesl\"] = json.load(f)\n",
    "\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3423efae-dce0-4090-8454-647fc2abc14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: need to `pip install pint-xarray` as it is not in dscim-epa environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ca44be82-e008-44f2-a48f-889007449ffc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import dask.config\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pint_xarray\n",
    "import xarray as xr\n",
    "import importlib  \n",
    "\n",
    "ps = Settings()\n",
    "sesl_p = ps.PARAMS[\"sesl\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eff7e8fd-c96c-4a7a-9abd-856b87ab3c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dangendorf(path):\n",
    "    msl_hist = pd.read_fwf(\n",
    "        path,\n",
    "        skiprows=1,\n",
    "        usecols=[0, 1],\n",
    "        names=[\"year\", \"GMSL\"],\n",
    "    )\n",
    "    dt = pd.to_datetime(msl_hist.year.astype(int), format=\"%Y\") + pd.to_timedelta(\n",
    "        (msl_hist.year - msl_hist.year.astype(int)) * 365.25, unit=\"d\"\n",
    "    )\n",
    "    msl_hist = pd.Series(msl_hist.GMSL.values, index=dt)\n",
    "    msl_hist.index.name = \"date\"\n",
    "\n",
    "    # center at 1995-2014 mean\n",
    "    msl_hist_yr = msl_hist.resample(\"y\").mean()\n",
    "    msl_hist_yr.index = msl_hist_yr.index.year\n",
    "    msl_hist_rolling = msl_hist_yr.rolling(19, center=True).mean()\n",
    "    msl_hist -= msl_hist_rolling.loc[2005]\n",
    "\n",
    "    msl_hist.name = \"gmsl_rel_2005_mm\"\n",
    "    return msl_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09b1006-abeb-4599-a84e-6425b71299da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client, LocalCluster\n",
    "\n",
    "cluster = LocalCluster()\n",
    "client = Client(cluster)\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "44901e6d-331e-4b61-a672-ebc50691b948",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "FAIR_RFF_STUB = (\n",
    "    \"ar6_rff_fair162_control_pulse_{gas_stub}*_emis_conc_rf_temp_lambdaeff_\"\n",
    "    \"ohc_emissions-driven_naturalfix_{version}.nc\"\n",
    ")\n",
    "FAIR_RFF_MEDIAN_STUB = FAIR_RFF_STUB.replace(\"iter0-19\", \"medianparams\")\n",
    "\n",
    "# attrs\n",
    "DESCRIPTION = \"Simulations of GMSL relative to a 1991-2009 mean, from 2020 to 2500, consistent with FAIR GMST simulations \"\n",
    "DESCRIPTION_RCP = DESCRIPTION + \"of the RCP scenarios\"\n",
    "DESCRIPTION_RFF = DESCRIPTION + \"of the RFF emissions ensemble\"\n",
    "\n",
    "METHOD_RCP = 'A Semi-Empirical Sea Level (SESL) model (github.com/bobkopp/SESL) probabilistically converts a GMST time-series to a GMSL time series. This is applied to both control and pulse scenarios and the difference is taken. This \"pulse delta\" is then added to a baseline trajectory taken from GMSL simulations used in IPCC AR6 (provided via personal correspondance from Bob Kopp). Draws of SESL/FAIR model \"pulse delta\" and draws of AR6 \"possibilistic\" projections are aligned before summing by quantile-matching the 2300 GMSL projected under the control FAIR scenario with that of the AR6 projections. The parameter distribution used for the SESL model was provided via personal correspondance from Bob Kopp. All other SESL input data is taken from the github repo. The AR6 projections end in 2300. To project 2300-2500, we align the SESL control scenarios to the AR6 projections (using the previously defined quantile-matching pairs) and allow SLR to evolve based on the SESL control runs from 2300-2500. Finally, to convert from the AR6 reference period (1996-2014) to the reference period used in the rest of the coastal impacts work (1991-2009), we use a reconstruction of historical sea levels from Dangendorf et al. 2019 (https://www.nature.com/articles/s41558-019-0531-8#MOESM2). We take the means of these two periods and use that offset to adjust the GMSL projections. For the \"median\" runs, we use a temperature simulation from median FAIR parameters. For SESL, we take the median parameters from the two temperature reconstruction datasets (Marcott and Mann), calculate the resulting sea level values, and then take the mean of these two outputs.'\n",
    "\n",
    "METHOD_RFF = (\n",
    "    METHOD_RCP\n",
    "    + \"\"\"\n",
    "\n",
    "Because the baseline trajectories are only available for the RCPs, we emulate a baseline for each RFF emissions ensemble member. We do this by taking the weighted average of the GMSL of the two bounding RCPs surrounding each RFF scenario. The ordering is determined by integrated radiative forcing from 2016 (the first year of deviation in the RCPs). This forcing is as output from FAIR. When the RFF draw falls outside the range of the RCPs included in the AR6 outputs, the GMSL from the closest RCP (in integrated forcing space) is chosen.\"\"\"\n",
    ")\n",
    "\n",
    "HISTORY = \"\"\"version 3.0: RCP runs. Initial model. Version starts at 3.0 to align with current version of FAIR GMST outputs.\n",
    "version 3.1: RCP runs. Offsetting to a 0 GMSL in 2000 baseline (previously was 2005). This is to match the 0 point of LocalizeSL and the projections.\n",
    "version 4.0: RCP runs. Correct bad AR6 baseline input due to bug bringing all scenarios to the mean in 2100 for workflow 0. Version bump occurs to keep pace with FAIR temperature version increase.\n",
    "version 4.0_Jan212022: RCP runs. Model GMSL from pulses of other GHGs. Updated FACTS distributions.\n",
    "version 5.0:  RFF runs. Same as v4.0 but for RFF outputs. First version to output both RFF and RCP-based GMSL datasets.\n",
    "version 5.0.1:  RFF runs. Uses v5.0.1 of RFF FAIR outputs (fixed FAIR bug from v5.0 related to RFF outputs only)\n",
    "version 5.02:  RFF runs. Uses v5.02 of RFF FAIR outputs. Update RFF-RCP matching algorithm to use SESL-GMSL as the index rather than radiative forcing. Also update such that if the 5 RCPs paired with the same FAIR parameters do not bound the RFF draw, search first across FAIR parameter draws and then across nearby years. See User Manual for more details.\n",
    "version 5.02_Jan72022: RFF runs. Model GMSL from multiple pulse years.\n",
    "version 5.02_Jan222022:  RFF runs. Model GMSL from pulses of other GHGs. Updated FACTS distributions\n",
    "version 5.03_Feb072022: RFF runs with RFF-FaIR climate param pairings. Model GMSL from pulses of CO2, CH4, N2O.\n",
    "\"\"\"\n",
    "\n",
    "AUTHOR = \"Ian Bolliger\"\n",
    "CONTACT = \"ibolliger@rhg.com\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe4e224-353d-4e0d-95e8-4c94f04cc2da",
   "metadata": {
    "tags": []
   },
   "source": [
    "## RCP-based SESL workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "20f90c3b-7a08-43bf-9d5c-7682c045f0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_runtype(da):\n",
    "    return xr.concat(\n",
    "        (\n",
    "            da.sel(pulse_year=2020, runtype=\"control\", drop=True).expand_dims(\n",
    "                pulse_year=[0]\n",
    "            ),\n",
    "            da.sel(runtype=\"pulse\", drop=True),\n",
    "        ),\n",
    "        dim=\"pulse_year\",\n",
    "    )\n",
    "\n",
    "\n",
    "def unflatten_runtype(da):\n",
    "    control = da.sel(pulse_year=0, drop=True).expand_dims(pulse_year=da.pulse_year[1:])\n",
    "    pulse = da.drop_sel(pulse_year=0)\n",
    "    return xr.concat(\n",
    "        [control, pulse], dim=pd.Index([\"control\", \"pulse\"], name=\"runtype\")\n",
    "    )\n",
    "\n",
    "\n",
    "def quantile_map_sesl_and_baseline(baseline, sesl_sl):\n",
    "\n",
    "    # get ordering of SESL predictions for no-pulse scenario\n",
    "    order = sesl_sl.simulation.sortby(sesl_sl.squeeze(drop=True))\n",
    "\n",
    "    # get quantiles that we want to match between ar6 baselines and SESL projections\n",
    "    n_samples = len(order)\n",
    "    quantile_bounds = np.linspace(0, 1, n_samples + 1)\n",
    "    quantiles = (quantile_bounds[:-1] + quantile_bounds[1:]) / 2\n",
    "    this_baseline = baseline.quantile(q=quantiles, dim=\"sample\").rename(\n",
    "        quantile=\"simulation\"\n",
    "    )\n",
    "    this_baseline[\"simulation\"] = order\n",
    "    return this_baseline.sortby(\"simulation\")\n",
    "\n",
    "\n",
    "def get_bound_wts(trg_vals, src_vals, dim=\"rcp\", year=None):\n",
    "\n",
    "    # find the bounding rcp's and take a weighted average. If no bounding, just take value\n",
    "    # from closest rcp\n",
    "    diff = trg_vals - src_vals\n",
    "    lb = diff.where(diff >= 0, np.inf)\n",
    "    no_lb = np.isinf(lb).all(dim=dim)\n",
    "    lb = lb.idxmin(dim).where(~no_lb, src_vals.idxmin(dim).broadcast_like(no_lb))\n",
    "    ub = diff.where(diff <= 0, -np.inf)\n",
    "    no_ub = np.isinf(ub).all(dim=dim)\n",
    "    ub = ub.idxmax(dim).where(~no_ub, src_vals.idxmax(dim).broadcast_like(no_ub))\n",
    "\n",
    "    assert not (no_lb & no_ub & trg_vals.notnull()).any()\n",
    "\n",
    "    lb_val = src_vals.sel({dim: lb}, drop=True)\n",
    "    ub_val = src_vals.sel({dim: ub}, drop=True)\n",
    "\n",
    "    full_range = ub_val - lb_val\n",
    "    assert (ub_val.where(full_range == 0, 0) == lb_val.where(full_range == 0, 0)).all()\n",
    "\n",
    "    ub_wt = ((trg_vals - lb_val) / full_range).where(full_range != 0, 1)\n",
    "\n",
    "    return xr.Dataset({\"lb\": lb, \"ub\": ub, \"ub_wt\": ub_wt})\n",
    "\n",
    "\n",
    "def quantile_map_rff(trg_vals, src_vals, baseline_rcp, wt_ds, dim=\"runid\"):\n",
    "    lb_vals = []\n",
    "    ub_vals = []\n",
    "    for this_sp in trg_vals[dim]:\n",
    "        this_trg_vals = trg_vals.sel({dim: this_sp})\n",
    "        for lst, da in [(lb_vals, wt_ds.lb), (ub_vals, wt_ds.ub)]:\n",
    "            this_src_vals = src_vals.sel(rcp=da.sel({dim: this_sp}), drop=True)\n",
    "            this_baseline_rcp = baseline_rcp.sel(rcp=da.sel({dim: this_sp}), drop=True)\n",
    "            this_sim = np.abs(this_trg_vals - this_src_vals).idxmin(\"simulation\")\n",
    "            lst.append(this_baseline_rcp.sel(simulation=this_sim))\n",
    "\n",
    "    lb_vals = xr.concat(lb_vals, dim=dim)\n",
    "    ub_vals = xr.concat(ub_vals, dim=dim)\n",
    "    \n",
    "    print(\"this_trg_vals\", this_trg_vals.coords)\n",
    "    print(\"this_src_vals\", this_src_vals.coords)\n",
    "    print(\"this_baseline_rcp\", this_baseline_rcp.coords)\n",
    "    print(\"this_sim\", this_sim.coords)\n",
    "    \n",
    "    return wt_ds.ub_wt * ub_vals + (1 - wt_ds.ub_wt) * lb_vals "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1a5e4d4f-381e-4b00-880e-dc7a057fbd44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import ceil\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "\n",
    "from math import ceil, floor\n",
    "from typing import Sequence, Union\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "from scipy.linalg import toeplitz\n",
    "from scipy.io import loadmat\n",
    "\n",
    "\n",
    "def calc_temp(\n",
    "    data: xr.Dataset,\n",
    "    T_err: Union[str, None],\n",
    "    T_num: int,\n",
    "    n_samples: int,\n",
    "    tau_ar1: float = 10,\n",
    "    random_state: Union[int, None] = 0,\n",
    ") -> xr.DataArray:\n",
    "    \"\"\"Simulate draws of historical temperature time series based on AR1 processes.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : :class:`xarray.Dataset`\n",
    "        Output of ``load_data_SESL`` function. Contains mean estimate and standard\n",
    "        deviation for each year.\n",
    "    T_err : str or None,\n",
    "        Approach to simulating the time series using the standard deviation. Currently,\n",
    "        only ``ar1ts`` is supported:\n",
    "            - ``ar1ts``: AR(1) Parameter timescale == exp(-abs(t2-t1)/timescale)\n",
    "            - ``ar1``: T as AR(1) process with sigma as \"default\"\n",
    "            - ``default``: T + random noise as in KE11\n",
    "            - ``no``: Don't add uncertainty\n",
    "    T_num : int\n",
    "        Number of simulated time series to create\n",
    "    n_samples : int\n",
    "        Number of draws of the parameter posteriors\n",
    "    tau_ar1 : float, optional\n",
    "        If ``T_err==ar1ts``, this is the ``timescale`` parameter. Otherwise, ignored.\n",
    "    random_state : int, optional\n",
    "        If set, controls the random state for the :function:`numpy.random.default_rng`\n",
    "        function used to generate time series draws. If None, will result in\n",
    "        non-deterministic outputs\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    :class:`xarray.DataArray`\n",
    "        Contains ``T_num`` sims of historical annual mean GMST values.\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(random_state)\n",
    "    if T_err == \"ar1ts\":\n",
    "        T = data.T\n",
    "        err_vec = T.sel(kind=\"err\").values\n",
    "        err_sq = np.expand_dims(err_vec, 1) * np.expand_dims(err_vec, 0)\n",
    "        yr_vec = T.T_year.values\n",
    "        yr_vec_neg_diff_norm = -np.abs(\n",
    "            (np.expand_dims(yr_vec, 1) - np.expand_dims(yr_vec, 0)) / tau_ar1\n",
    "        )\n",
    "        cov_ar1 = err_sq * np.exp(yr_vec_neg_diff_norm)\n",
    "        sims = rng.multivariate_normal(\n",
    "            T.sel(kind=\"val\"), cov_ar1, size=(T_num, n_samples)\n",
    "        )\n",
    "        return xr.DataArray(\n",
    "            sims.T,\n",
    "            coords={\n",
    "                \"T_sim_id\": np.arange(sims.shape[0]),\n",
    "                \"year\": T.T_year.values,\n",
    "                \"sample\": np.arange(n_samples),\n",
    "            },\n",
    "            dims=[\"year\", \"sample\", \"T_sim_id\"],\n",
    "        )\n",
    "    elif T_err == \"no\":\n",
    "        return data.T.sel(kind=\"val\").rename(T_year=\"year\")\n",
    "    raise NotImplementedError\n",
    "\n",
    "\n",
    "def calc_T0(\n",
    "    T_sims: xr.Dataset,\n",
    "    historical_data: xr.Dataset,\n",
    "    params: xr.Dataset,\n",
    "    optim_T0: bool,\n",
    "    model: str,\n",
    "    T0_period_end: int = -1800,\n",
    ") -> xr.Dataset:\n",
    "    \"\"\"Calculate draws of ``T0`` parameter from historical temperature draws.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    T_sims : :class:`xarray.Dataset`\n",
    "        Output of :func:`calc_temp`. Contains draws of historical temps.\n",
    "    historical_data : :class:`xarray.Dataset`\n",
    "        Output of :func:`pySESL.io.load_data_SESL`. Contains mean and SDs for temp and\n",
    "        sea level reconstructions.\n",
    "    params : :class:`xarray.Dataset`\n",
    "        Output of :func:`pySESL.io.load_params`. Contains posterior distributions of\n",
    "        trained SESL model parameters.\n",
    "    optim_T0 : bool\n",
    "        Whether to use the optimized T0(0) posterior distribution from ``params``\n",
    "    model : \"CRdecay\", \"ConstRate\", \"CRovTau\", \"TwoTau\", or \"simpel\"\n",
    "        Which model was used to train SESL model and generate ``params``.\n",
    "    T0_period_end : int, optional\n",
    "        Ending year of period used to calculate an initial T0(0). Default -1800.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    :class:`xarray.Dataset`\n",
    "        Contains the T0 parameter for each year and for each of the sims of historical\n",
    "        GMST contained in ``T_sims``\n",
    "    \"\"\"\n",
    "    if optim_T0:\n",
    "        T0_rnd = params.T01\n",
    "    else:\n",
    "        T0_rnd = 0\n",
    "    tau1 = params.tau\n",
    "    # tau2 = params.tau_c\n",
    "\n",
    "    n_yrs = len(T_sims.year)\n",
    "\n",
    "    def toepify(arr):\n",
    "        return toeplitz(arr, np.concatenate((arr[:1], np.zeros(len(arr) - 1))))\n",
    "\n",
    "    # if use_Mar_T0 was used\n",
    "    if \"T0burnin\" in historical_data.data_vars:\n",
    "        n_burnin = historical_data.T0burnin.item()\n",
    "        yrs1 = historical_data.T_year[1].item() - historical_data.T_year[0].item()\n",
    "        yrs2 = historical_data.T_year[-1].item() - historical_data.T_year[-2].item()\n",
    "        tau1_1 = tau1 / yrs1\n",
    "        tau1_2 = tau1 / yrs2\n",
    "        tau1_ = xr.concat([tau1_1, tau1_2], dim=pd.Index([\"T0\", \"T\"], name=\"T_type\"))\n",
    "        G = ((1 - 1 / tau1_) * xr.ones_like(T_sims.year)) ** xr.DataArray(\n",
    "            np.arange(n_yrs), dims=[\"year\"]\n",
    "        )\n",
    "        G_M = xr.apply_ufunc(\n",
    "            toepify,\n",
    "            G,\n",
    "            input_core_dims=[[\"year\"]],\n",
    "            output_core_dims=[[\"year\", \"year2\"]],\n",
    "            vectorize=True,\n",
    "        )\n",
    "\n",
    "        GM_T0 = G_M.sel(T_type=\"T0\").isel(year2=slice(None, n_burnin))\n",
    "        GM_T = G_M.sel(T_type=\"T\").isel(year2=slice(n_burnin, None))\n",
    "        G_M1 = xr.concat((GM_T0, GM_T), dim=\"year2\")\n",
    "\n",
    "        temp_1_T0 = T_sims.isel(year=slice(None, n_burnin)) / tau1_1\n",
    "        temp_1_T = T_sims.isel(year=slice(n_burnin, None)) / tau1_2\n",
    "        temp_1 = xr.concat((temp_1_T0, temp_1_T), dim=\"year\")\n",
    "        temp_1[{\"year\": 0}] = (\n",
    "            T_sims.isel(year=(historical_data.T_year <= T0_period_end).values).mean(\n",
    "                \"year\"\n",
    "            )\n",
    "            + T0_rnd\n",
    "        )\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    if model == \"TwoTau\":\n",
    "        raise NotImplementedError\n",
    "\n",
    "    T01 = xr.dot(G_M1, temp_1.rename(year=\"year2\"), dims=[\"year2\"])\n",
    "    return T01\n",
    "\n",
    "\n",
    "def calc_sl(\n",
    "    T_sims: xr.DataArray,\n",
    "    T0_sims: xr.DataArray,\n",
    "    params: xr.Dataset,\n",
    "    model: str,\n",
    "    period: Sequence,\n",
    "    interp_method: str = \"nearest\",\n",
    ") -> tuple:\n",
    "    \"\"\"Calculate draws of sea level and ``c`` parameter using historical temperature\n",
    "    draws.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    T_sims : :class:`xarray.Dataset`\n",
    "        Output of :func:`calc_temp`. Contains draws of historical temps.\n",
    "    T0_sims : :class:`xarray.Dataset`\n",
    "        Output of :func:`calc_T0`. Contains T0 associated with historical T draws.\n",
    "    params : :class:`xarray.Dataset`\n",
    "        Output of :func:`pySESL.io.load_params`. Contains posterior distributions of\n",
    "        trained SESL model parameters.\n",
    "    model : \"CRdecay\", \"ConstRate\", \"CRovTau\", \"TwoTau\", or \"simpel\"\n",
    "        Which model was used to train SESL model and generate ``params``.\n",
    "    period : length-2 array-like\n",
    "        Period of data to include in results\n",
    "    interp_method : str, optional\n",
    "        Interpolation method used to annualize ``T_sims`` and ``T0_sims`` variables.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    sea : :class:`xarray.DataArray`\n",
    "        Sea Level by year for each parameter sample X temperature reconstruction sample\n",
    "    dsea : :class:`xarray.DataArray`\n",
    "        Annual change in sea Level by year for each parameter sample X temperature\n",
    "        reconstruction sample\n",
    "    c : :class:`xarray.DataArray`\n",
    "        Value of ``c`` parameter by year for each parameter sample\n",
    "    T_sims, T0_sims : :class:`xarray.DataArray`\n",
    "        Same as the input ``T_sims`` and ``T0_sims`` but interpolated to annual values\n",
    "        using ``interp_method`` and clipped to range bounded by ``period`` and\n",
    "        ``calibperiod``\n",
    "    \"\"\"\n",
    "\n",
    "    if model != \"CRdecay\":\n",
    "        raise NotImplementedError\n",
    "\n",
    "    T_sims, T0_sims = resize_T(period, T_sims, T0_sims, interp_method=interp_method)\n",
    "    g = 1 - 1 / params.tau_c\n",
    "    G = g ** xr.DataArray(\n",
    "        np.arange(T_sims.year.size), coords={\"year\": T_sims.year}, dims=[\"year\"]\n",
    "    )\n",
    "    c = params.c * G\n",
    "    dsea = c + params.a * (T_sims - T0_sims)\n",
    "    sea = dsea.cumsum(\"year\")\n",
    "\n",
    "    return sea, dsea, c, T_sims, T0_sims\n",
    "\n",
    "\n",
    "def resample_ics(ics, sim_ids, sesl_trained_params):\n",
    "    \"\"\"Resample ICs such that they have the same number of samples as are in the\n",
    "    temperature projections ``temps``.\n",
    "\n",
    "    TODO: finish docstring\n",
    "    \"\"\"\n",
    "    # get T0_2000, T_ref in index of FAIR samples\n",
    "    def resample_full(ds):\n",
    "        return ds.stack(simulation=[\"T_sim_id\", \"sample\", \"T_data\"]).isel(\n",
    "            simulation=slice(None, len(sim_ids))\n",
    "        )\n",
    "\n",
    "    T0_2000, T_ref = list(map(resample_full, [ics.T0_2000, ics.T_ref]))\n",
    "    assert (T0_2000.simulation == T_ref.simulation).all()\n",
    "\n",
    "    # get the appropriate parameters for each of the 3k sims\n",
    "    def resample_partial(ds):\n",
    "        out = ds.stack(simulation=[\"sample\", \"T_data\"]).sel(\n",
    "            simulation=pd.MultiIndex.from_arrays(\n",
    "                (T0_2000.sample.values, T0_2000.T_data.values),\n",
    "                names=[\"sample\", \"T_data\"],\n",
    "            )\n",
    "        )\n",
    "        if type(out) == xr.core.dataset.Dataset:\n",
    "            arrays = []\n",
    "            for i in list(out.keys()):\n",
    "                t1 = out[i]\n",
    "                t1[\"simulation\"] = sim_ids\n",
    "                arrays = arrays + [t1.copy()]\n",
    "            out = xr.merge(arrays)\n",
    "        else:\n",
    "            out[\"simulation\"] = sim_ids\n",
    "        return out\n",
    "\n",
    "    param_sims, c_2000 = list(map(resample_partial, [sesl_trained_params, ics.c_2000]))\n",
    "    T0_2000[\"simulation\"] = sim_ids\n",
    "    T_ref[\"simulation\"] = sim_ids\n",
    "    out_params = xr.merge((T0_2000, c_2000, T_ref, param_sims))\n",
    "    return out_params\n",
    "\n",
    "def get_ics(n_fair_sims, sesl_trained_params, sesl_hyperparams, sesl_input_dir):\n",
    "    \"\"\"Get initial conditions T0_2000 and c_2000 necessary for projecting using SESL.\n",
    "    Also return T_ref, or the mean temperature over the reference period as defined in\n",
    "    ``sesl_hyperparams``.\n",
    "\n",
    "    TODO: finish docstring\n",
    "    \"\"\"\n",
    "    # figure out how many historical temp draws to use\n",
    "    n_sesl_samps = len(sesl_trained_params.sample)\n",
    "    n_sesl_data_samps = len(sesl_trained_params.T_data)\n",
    "\n",
    "    T_num = ceil(n_fair_sims / n_sesl_samps / n_sesl_data_samps)\n",
    "\n",
    "    T0_2000 = []\n",
    "    T_ref = []\n",
    "    c_2000 = []\n",
    "\n",
    "    T_ref_range = np.arange(\n",
    "        sesl_hyperparams[\"T_bias_correction_period\"][0],\n",
    "        sesl_hyperparams[\"T_bias_correction_period\"][1] + 1,\n",
    "    )\n",
    "\n",
    "    for dat in sesl_hyperparams[\"T_data\"]:\n",
    "        historical_data = load_data_SESL(\n",
    "            sesl_input_dir / (sesl_hyperparams[\"SL_data\"] + \".mat\"),\n",
    "            sesl_input_dir / (dat + \".mat\"),\n",
    "            sesl_hyperparams[\"use_cov\"],\n",
    "            sesl_hyperparams[\"use_Mar_T0\"],\n",
    "            Mar_fpath=sesl_input_dir / \"Marcott13_RegEM-HC3_20.mat\",\n",
    "            T_err_sc=sesl_hyperparams[\"T_err_sc\"],\n",
    "            cov_tau=sesl_hyperparams[\"cov_tau\"],\n",
    "            no_neg_cov=sesl_hyperparams[\"no_neg_cov\"],\n",
    "            baseperiod=sesl_hyperparams[\"baseperiod\"],\n",
    "            T0_temp_level=sesl_hyperparams[\"T0_temp_level\"],\n",
    "            T0_period_st=sesl_hyperparams[\"T0_period\"][0],\n",
    "        )\n",
    "\n",
    "        T_sims = calc_temp(\n",
    "            historical_data,\n",
    "            sesl_hyperparams[\"T_err\"],\n",
    "            T_num,\n",
    "            sesl_trained_params.dims[\"sample\"],\n",
    "            tau_ar1=sesl_hyperparams[\"tau_ar1\"],\n",
    "        )\n",
    "\n",
    "        T_ref.append(T_sims.interp(year=T_ref_range).mean(\"year\"))\n",
    "\n",
    "        if dat[:4] == \"Mann\":\n",
    "            dat_short = \"Mn\"\n",
    "        elif dat[:4] == \"Marc\":\n",
    "            dat_short = \"Mar\"\n",
    "        else:\n",
    "            raise NotImplementedError(dat)\n",
    "        T0_sims = calc_T0(\n",
    "            T_sims,\n",
    "            historical_data,\n",
    "            sesl_trained_params.sel(T_data=dat_short, drop=True),\n",
    "            sesl_hyperparams[\"optim_T0\"],\n",
    "            sesl_hyperparams[\"model\"],\n",
    "            T0_period_end=sesl_hyperparams[\"T0_period\"][1],\n",
    "        )\n",
    "        T0_2000.append(T0_sims.interp(year=2000).drop(\"year\"))\n",
    "\n",
    "        _, _, c, _, _ = calc_sl(\n",
    "            T_sims,\n",
    "            T0_sims,\n",
    "            sesl_trained_params.sel(T_data=dat_short, drop=True),\n",
    "            sesl_hyperparams[\"model\"],\n",
    "            [\n",
    "                min(sesl_hyperparams[\"period\"][0], sesl_hyperparams[\"calibperiod\"][0]),\n",
    "                max(sesl_hyperparams[\"period\"][1], sesl_hyperparams[\"calibperiod\"][1]),\n",
    "            ],\n",
    "        )\n",
    "\n",
    "        c_2000.append(c.sel(year=2000, drop=True))\n",
    "\n",
    "    dim = pd.Index(sesl_hyperparams[\"T_data\"], name=\"T_data\")\n",
    "    T0_2000, c_2000, T_ref = list(\n",
    "        map(\n",
    "            lambda x: xr.concat(x, dim=dim),\n",
    "            [T0_2000, c_2000, T_ref],\n",
    "        )\n",
    "    )\n",
    "\n",
    "    new_T_data = T0_2000.T_data.str[:3]\n",
    "    new_T_data = new_T_data.where(new_T_data == \"Mar\", \"Mn\")\n",
    "    T0_2000[\"T_data\"] = new_T_data\n",
    "    c_2000[\"T_data\"] = new_T_data\n",
    "    T_ref[\"T_data\"] = new_T_data\n",
    "\n",
    "    return xr.Dataset({\"T0_2000\": T0_2000, \"c_2000\": c_2000, \"T_ref\": T_ref})\n",
    "\n",
    "\n",
    "def bias_correct_temps(temps, bc_period, T_ref, first_year=None):\n",
    "    \"\"\"Bias correct a temperature dataset such that it matches with the reference period\n",
    "    used to calculate the T0_2000 initial condition.\n",
    "\n",
    "    TODO: finish docstring\n",
    "    \"\"\"\n",
    "    return (temps - temps.sel(year=slice(*bc_period)).mean(\"year\") + T_ref).sel(\n",
    "        year=slice(first_year, None)\n",
    "    )\n",
    "\n",
    "\n",
    "def project_sesl(temps, params):\n",
    "    \"\"\"Project GMSL given input temperatures and params (including initial conditions).\n",
    "    Note that ``temps`` must already be corrected to have the same reference period as\n",
    "    ``params.T0_2000``.\n",
    "\n",
    "    TODO: finish docstring\n",
    "    \"\"\"\n",
    "    temp_arr = temps.copy()\n",
    "    sl = 0 * temp_arr\n",
    "\n",
    "    a = params.a\n",
    "    tau = params.tau\n",
    "    tau_c = params.tau_c\n",
    "\n",
    "    T0 = params.T0_2000.broadcast_like(temp_arr.isel(year=0, drop=True)).copy()\n",
    "    c = params.c_2000.broadcast_like(tau_c).copy()\n",
    "\n",
    "    # iterate over years\n",
    "    for yr in sl.year:\n",
    "        TminusT0 = temp_arr.sel(year=yr, drop=True) - T0\n",
    "\n",
    "        # update SL\n",
    "        if yr > sl.year[0]:\n",
    "            sl.loc[{\"year\": yr}] = sl.sel(year=yr - 1, drop=True) + a * TminusT0 + c\n",
    "\n",
    "        # update T0\n",
    "        T0 += 1 / tau * TminusT0\n",
    "\n",
    "        # update c\n",
    "        c *= 1 - 1 / tau_c\n",
    "\n",
    "    # convert to DataArray\n",
    "    return sl\n",
    "\n",
    "def resize_T(\n",
    "    period: Sequence, *das: xr.DataArray, interp_method: str = \"nearest\"\n",
    ") -> Sequence:\n",
    "    \"\"\"Interpolate DataArrays of values at (potentially varying) time intervals to\n",
    "    annual time series, and clip them\n",
    "\n",
    "    Parameters\n",
    "    ---------\n",
    "    period : length-2 array-like\n",
    "        Starting and ending values for desired period of output DataArrays\n",
    "    interp_method : str, optional\n",
    "        Interpolation method to use to annualize inputs. Default is \"nearest\".\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tuple\n",
    "        Tuple of DataArrays of same length as ``das``, interpolated and clipped\n",
    "    \"\"\"\n",
    "\n",
    "    da = das[0]\n",
    "\n",
    "    fyr = max(da.year[0].item(), period[0])\n",
    "    lyr = period[1]\n",
    "\n",
    "    out_range = da.year.isel(year=(da.year >= fyr) & (da.year <= lyr))\n",
    "    diffs = out_range.diff(\"year\")\n",
    "    yrs_st = diffs[0]\n",
    "    yrs_end = diffs[-1]\n",
    "    yrs_out = np.arange(\n",
    "        out_range[0] - floor((yrs_st - 1) / 2),\n",
    "        out_range[-1] + ceil((yrs_end - 1) / 2) + 1,\n",
    "    )\n",
    "\n",
    "    return list(\n",
    "        map(\n",
    "            lambda x: x.interp(\n",
    "                year=yrs_out,\n",
    "                method=interp_method,\n",
    "                kwargs={\"fill_value\": \"extrapolate\"},\n",
    "            ),\n",
    "            das,\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "def load_data_SESL(\n",
    "    sl_fpath: Union[str, Path],\n",
    "    T_fpath: Union[str, Path],\n",
    "    use_cov: bool,\n",
    "    use_Mar_T0: bool,\n",
    "    Mar_fpath: Union[str, Path, None] = None,\n",
    "    T_err_sc: float = 1,\n",
    "    cov_tau: float = 100,\n",
    "    no_neg_cov: bool = True,\n",
    "    baseperiod: Sequence[int] = [1400, 1800],\n",
    "    T0_temp_level: float = 100,\n",
    "    T0_period_st: int = -2000,\n",
    ") -> xr.Dataset:\n",
    "    \"\"\"Load historical temperature and sea level reconstructions\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    sl_fpath : str or :class:`pathlib.Path`\n",
    "        Path to sea level reconstruction input ``.mat`` file.\n",
    "    T_fpath : str or :class:`pathlib.Path`\n",
    "        Path to temperature reconstruction input ``.mat`` file.\n",
    "    use_cov : bool\n",
    "        If True, use covariance matrix of SL reconstruction data (if existing) to\n",
    "        estimate likelihood of parameter set.\n",
    "    use_Mar_T0 : bool\n",
    "        If True, use Marcott long-running temperature reconstruction to calculate ``T0``\n",
    "        value until reconstruction at ``T_fpath`` starts.\n",
    "    Mar_fpath : str or :class:`pathlib.Path` or None, optional\n",
    "        Path to Marcott sea level reconstruction input ``.mat`` file. Only used if\n",
    "        ``use_Mar_T0`` is True.\n",
    "    T_err_sc : float, optional\n",
    "        Scaling factor for temperature error uncertainty.\n",
    "    cov_tau : float, optional\n",
    "        Time scale for covariance. If not null, take the elementwise product of the\n",
    "        covariance and a tapering function exp(-delta(t)/cov_tau). Only used if\n",
    "        ``use_cov`` is True.\n",
    "    no_neg_cov : bool, optional\n",
    "        Bound covariance matrix to be non-negative. Default True.\n",
    "    baseperiod : array-like, optional\n",
    "        Reference period used for sea level data. Data are normed to have 0 mean over\n",
    "        this period. Default [1400, 1800].\n",
    "    T0_temp_level : int, optional\n",
    "        If ``use_Mar_T0`` is True, number of years over which to harmonize the mean of\n",
    "        the Marcott T time series and time series at ``T_fpath`` in order to calculate\n",
    "        T0 from Marcott.\n",
    "    T0_period_st : int, optional\n",
    "        Starting year of period used to calculate an initial T0(0).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    :class:`xarray.Dataset`\n",
    "        Contains the processed estimated value and error for the temperature\n",
    "        reconstruction at ``T_fpath``, the sea level reconstruction at ``sl_fpath``, and\n",
    "        the derived T0 timeseries using ``sl_fpath`` and (optionally) the long-running\n",
    "        Marcott reconstruction\n",
    "    \"\"\"\n",
    "\n",
    "    # load SL proxy data\n",
    "    sl_data = loadmat(sl_fpath, squeeze_me=True)\n",
    "    sl = sl_data[\"sl\"]\n",
    "    proxy_sl = pd.DataFrame(\n",
    "        {\n",
    "            \"val\": (sl[:, 1] / 10).astype(np.float64),\n",
    "            \"err\": (sl[:, 2] / 10).astype(np.float64),\n",
    "        },\n",
    "        index=pd.Index(sl[:, 0].astype(np.int16), name=\"year\"),\n",
    "    )\n",
    "    C = (sl_data[\"C\"] / 100).astype(np.float64)\n",
    "    C += np.eye(len(C)) * np.finfo(C.dtype).eps\n",
    "\n",
    "    if use_cov:\n",
    "        if cov_tau is not None:\n",
    "            Csc = np.exp(\n",
    "                -np.abs(\n",
    "                    np.expand_dims(proxy_sl.index.values, 0)\n",
    "                    - np.expand_dims(proxy_sl.index.values, 1)\n",
    "                )\n",
    "                / cov_tau\n",
    "            )\n",
    "            C *= Csc\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "        if no_neg_cov:\n",
    "            C = np.maximum(C, 0)\n",
    "\n",
    "    # rebase proxy SL data to base period\n",
    "    proxy_sl[\"val\"] -= proxy_sl.loc[baseperiod[0] : baseperiod[1], \"val\"].mean()\n",
    "\n",
    "    # convert to long format\n",
    "    proxy_sl = proxy_sl.stack()\n",
    "    proxy_sl.index = proxy_sl.index.rename(\"kind\", level=-1)\n",
    "    proxy_sl.name = \"sl\"\n",
    "\n",
    "    # load T reconstruction data\n",
    "    T = loadmat(T_fpath, squeeze_me=True)[\"T\"]\n",
    "    T = pd.DataFrame(\n",
    "        T[:, 1:3],\n",
    "        columns=[\"val\", \"err\"],\n",
    "        index=pd.Index(T[:, 0], name=\"year\").astype(np.int16),\n",
    "    )\n",
    "\n",
    "    # assert common timestep\n",
    "    dyr = np.diff(T.index)\n",
    "    assert len(np.unique(dyr)) == 1\n",
    "    dyr = dyr[0]\n",
    "\n",
    "    # scale by predefined scaling factor\n",
    "    T[\"err\"] *= T_err_sc\n",
    "\n",
    "    # convert to long format\n",
    "    T_long = T.stack()\n",
    "    T_long.index = T_long.index.rename(\"kind\", level=-1)\n",
    "    T_long.name = \"T\"\n",
    "\n",
    "    # aggregate into Dataset\n",
    "    data = xr.merge(\n",
    "        (\n",
    "            proxy_sl.to_xarray().rename(year=\"sl_year\"),\n",
    "            T_long.to_xarray().rename(year=\"T_year\"),\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Use Mar data for early T values if using for initializing T0\n",
    "    if use_Mar_T0:\n",
    "        T_mar = loadmat(Mar_fpath)[\"T\"]\n",
    "        T_mar = pd.DataFrame(\n",
    "            T_mar[:, 1:],\n",
    "            columns=[\"val\", \"err\"],\n",
    "            index=pd.Index(T_mar[:, 0], name=\"year\").astype(np.int16),\n",
    "        )\n",
    "        T_mar_overlap_mean = T_mar.loc[\n",
    "            T.index.min() : T.index.min() + T0_temp_level, \"val\"\n",
    "        ].mean()\n",
    "        T_overlap_mean = T.loc[: T.index.min() + T0_temp_level, \"val\"].mean()\n",
    "        T_mar[\"val\"] = T_mar[\"val\"] - T_mar_overlap_mean + T_overlap_mean\n",
    "        T_mar = T_mar.loc[: T.index.min() - int((dyr - 1) / 2)]\n",
    "\n",
    "        T0_temp = pd.concat((T_mar, T))\n",
    "\n",
    "        # only care about part after beginning of burnin period\n",
    "        T0_temp = T0_temp.loc[T0_period_st:]\n",
    "        T0burnin = (T0_temp.index < T.index.min()).sum()\n",
    "\n",
    "        # convert to long format\n",
    "        T0_temp = T0_temp.stack()\n",
    "        T0_temp.index = T0_temp.index.rename(\"kind\", level=-1)\n",
    "        T0_temp.name = \"T\"\n",
    "\n",
    "        data = data.drop([\"T\", \"T_year\"]).assign(\n",
    "            {\"T\": T0_temp.to_xarray().rename(year=\"T_year\")}\n",
    "        )\n",
    "        data[\"T0burnin\"] = T0burnin\n",
    "\n",
    "    C = xr.DataArray(\n",
    "        C,\n",
    "        dims=[\"sl_year\", \"sl_year_cov\"],\n",
    "        coords={\"sl_year\": data.sl_year.values, \"sl_year_cov\": data.sl_year.values},\n",
    "        name=\"sl_C\",\n",
    "    )\n",
    "    data = xr.merge((data, C))\n",
    "    return data\n",
    "\n",
    "\n",
    "def _load_params_from_struct(struct):\n",
    "    \"\"\"Load SESL parameter posterior distributions from a MATLAB struct.\"\"\"\n",
    "    return pd.DataFrame(\n",
    "        {\n",
    "            \"a\": struct[\"a\"].item(),\n",
    "            \"c\": struct[\"c\"].item(),\n",
    "            \"tau\": struct[\"tau\"].item(),\n",
    "            \"tau_c\": struct[\"tau_c\"].item(),\n",
    "            \"T01\": struct[\"T01\"].item(),\n",
    "        },\n",
    "        index=pd.Index(np.arange(len(struct[\"a\"].item())), name=\"sample\"),\n",
    "    ).to_xarray()\n",
    "\n",
    "def load_param_file(fpath: str) -> xr.Dataset:\n",
    "    \"\"\"Load posterior parameter distribution from a trained SESL model (run in the\n",
    "    MATLAB version of the codebase).\n",
    "    \"\"\"\n",
    "    data = loadmat(fpath, squeeze_me=True)[\"P\"]\n",
    "    mar = data[\"Mar\"].item()\n",
    "    mn = data[\"Mn\"].item()\n",
    "    return xr.concat(\n",
    "        [_load_params_from_struct(struct) for struct in [mar, mn]],\n",
    "        dim=pd.Index([\"Mar\", \"Mn\"], name=\"T_data\"),\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e98f7364-2ef5-493a-8d70-7602bb43e90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get temp projections from FAIR\n",
    "with open(Path(ps.PATH_HAZARD_GMST_FAIR_RCP), \"rb\") as f:\n",
    "    fair_temps_rcp = flatten_runtype(\n",
    "        xr.open_dataset(f).temperature.drop(\"scalar\").load()\n",
    "    )\n",
    "    \n",
    "with open(Path(ps.PATH_HAZARD_GMST_FAIR_RCP_MEDIAN), \"rb\") as f:\n",
    "    fair_temps_rcp_med = flatten_runtype(\n",
    "        xr.open_dataset(f).temperature.load()\n",
    "    ).expand_dims(simulation=1)\n",
    "# Load posterior of SESL parameters (pre-trained)\n",
    "with open(\n",
    "    Path(ps.DIR_HAZARD_SLR_SESL_RAW / \"Parameters.mat\"), \"rb\"\n",
    ") as f:\n",
    "    params = load_param_file(f)\n",
    "params_med = params.median(\"sample\").expand_dims(sample=1)\n",
    "\n",
    "# Get T0 initial condition for SESL projections\n",
    "ics_rcp = get_ics(\n",
    "    len(fair_temps_rcp.simulation), params, sesl_p, ps.DIR_HAZARD_SLR_SESL_RAW\n",
    ")\n",
    "ics_rcp_med = get_ics(1, params_med, sesl_p, ps.DIR_HAZARD_SLR_SESL_RAW)\n",
    "\n",
    "# Resample the SESL initial condition and bias correction factors to match up with the fair simulations\n",
    "param_sims_rcp = resample_ics(ics_rcp, fair_temps_rcp.simulation, params)\n",
    "param_sims_rcp_med = resample_ics(\n",
    "    ics_rcp_med, fair_temps_rcp_med.simulation, params_med\n",
    ")\n",
    "fair_temps_rcp = bias_correct_temps(\n",
    "    fair_temps_rcp,\n",
    "    sesl_p[\"T_bias_correction_period\"],\n",
    "    param_sims_rcp.T_ref,\n",
    "    first_year=2000,\n",
    ")\n",
    "fair_temps_rcp_med = bias_correct_temps(\n",
    "    fair_temps_rcp_med,\n",
    "    sesl_p[\"T_bias_correction_period\"],\n",
    "    param_sims_rcp_med.T_ref,\n",
    "    first_year=2000,\n",
    ")\n",
    "\n",
    "# run sim\n",
    "sl_rcp = project_sesl(fair_temps_rcp, param_sims_rcp)\n",
    "sl_rcp_med = project_sesl(fair_temps_rcp_med, param_sims_rcp_med)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1686628f-d207-433c-a010-bc936cdeb7e1",
   "metadata": {},
   "source": [
    "## Merge in AR6 baselines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d3277a8-874d-49b3-93cb-3b55c471bc58",
   "metadata": {},
   "source": [
    "### Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d5512b2d-797b-4349-ac42-803b8d6d3b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "baselines = (\n",
    "    xr.open_zarr(ps.PATH_HAZARD_SLR_GMSL_BASELINE_INT_SYNTH, chunks=None)\n",
    "    .sea_level_change.pint.quantify()\n",
    "    .pint.to(\"cm\")\n",
    "    .pint.dequantify()\n",
    "    .sel(workflow=[\"wf_1f\", \"wf_2f\"])\n",
    "    .dropna(\"rcp\", how=\"all\")\n",
    "    .stack(sample=[\"workflow\", \"samples\"])\n",
    "    .rename(years=\"year\")\n",
    ")\n",
    "\n",
    "baselines[\"sample\"] = np.arange(len(baselines.sample))\n",
    "baselines = baselines.interp(year=np.arange(baselines.year[0], baselines.year[-1] + 1))\n",
    "final_year = baselines.year.max().item() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b13818c4-0468-4948-be64-d0bc115db875",
   "metadata": {},
   "source": [
    "### Transform to a year 2000 baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24741564-eb45-4bff-b840-8441b2a3442a",
   "metadata": {},
   "source": [
    "AR6 projections use 1996-2014 datum, but all of our projected damages refer to slr above a 1991-2009 mean datum. So we use historical GMSL estimates from [Dangendorf et al. 2019 (Supplementary Data 1)](https://www.nature.com/articles/s41558-019-0531-8#MOESM2) to adjust the datums."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ca758e0f-c1d1-459d-80c7-871138d9ac8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "msl_hist = load_dangendorf(ps.PATH_HAZARD_SLR_GMSL_RAW_HIST)\n",
    "msl_hist_yr = msl_hist.resample(\"y\").mean()\n",
    "msl_hist_yr.index = msl_hist_yr.index.year\n",
    "msl_hist_rolling = msl_hist_yr.rolling(19, center=True).mean()\n",
    "offset_05_to_00 = (msl_hist_rolling[2005] - msl_hist_rolling[2000]) / 10\n",
    "baselines += offset_05_to_00 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b467fc77-07c0-4700-91f7-cbe9ca13ae88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get baseline for median sample\n",
    "baselines_med = baselines.median(\"sample\")\n",
    "extra_sims_med = sl_rcp_med.sel(year=slice(final_year, None)).squeeze(drop=True)\n",
    "baselines_med = xr.concat(\n",
    "    (\n",
    "        baselines_med.isel(year=slice(None, -1)),\n",
    "        extra_sims_med.sel(pulse_year=0, drop=True)\n",
    "        + baselines_med.sel(year=final_year, drop=True)\n",
    "        - extra_sims_med.sel(pulse_year=0, year=final_year, drop=True),\n",
    "    ),\n",
    "    dim=\"year\",\n",
    ") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5acea121-1ce0-4098-8a60-c3ce3e10c8ee",
   "metadata": {},
   "source": [
    "### Do quantile mapping to match SESL and AR6 runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b91dbbb4-cdc2-49bc-902c-e56b3f8b89e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# quantile map within each year\n",
    "sl_rcp_chunked = (\n",
    "    sl_rcp.sel(pulse_year=0, year=baselines.year, rcp=baselines.rcp)\n",
    "    .drop(\"pulse_year\")\n",
    "    .chunk({\"rcp\": 1, \"year\": 1})\n",
    ")\n",
    "baseline_rcp = (\n",
    "    baselines.chunk({\"rcp\": 1, \"year\": 1})\n",
    "    .map_blocks(\n",
    "        quantile_map_sesl_and_baseline, (sl_rcp_chunked,), template=sl_rcp_chunked\n",
    "    )\n",
    "    .load()\n",
    ") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c525e632-260e-45d5-8ba0-e1ab6b124059",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Interpolate to missing rcp460"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57eec42a-0b75-4ccc-a26e-70c6a046cb1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sl_rcp_chunked_to_interp = (\n",
    "    sl_rcp.sel(pulse_year=0, year=baselines.year)\n",
    "    .drop_sel(rcp=baselines.rcp)\n",
    "    .drop(\"pulse_year\")\n",
    "    .chunk({\"rcp\": 1, \"year\": 1})\n",
    "    .rename(rcp=\"tmp\")\n",
    ")\n",
    "rcp_wt_ds = sl_rcp_chunked_to_interp.map_blocks(\n",
    "    get_bound_wts,\n",
    "    (sl_rcp_chunked.chunk({\"rcp\": -1}),),\n",
    "    template=xr.Dataset(\n",
    "        {\n",
    "            \"lb\": sl_rcp_chunked_to_interp.astype(object),\n",
    "            \"ub\": sl_rcp_chunked_to_interp.astype(object),\n",
    "            \"ub_wt\": sl_rcp_chunked_to_interp,\n",
    "        }\n",
    "    ),\n",
    ").load()\n",
    "\n",
    "baseline_rcp_extra = quantile_map_rff(\n",
    "    sl_rcp_chunked_to_interp.rename(simulation=\"iter\").load(),\n",
    "    sl_rcp_chunked.load(),\n",
    "    baseline_rcp,\n",
    "    rcp_wt_ds.rename(simulation=\"iter\"),\n",
    "    dim=\"iter\",\n",
    ").rename(iter=\"simulation\", tmp=\"rcp\")\n",
    "\n",
    "baseline_rcp = xr.concat((baseline_rcp, baseline_rcp_extra), dim=\"rcp\").sel(\n",
    "    rcp=sl_rcp.rcp\n",
    ")\n",
    "interpolated = sl_rcp_chunked_to_interp.tmp.values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2ea990fe-3b4d-4ae4-8bb4-f3d45bebca9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = 'rcp'\n",
    "src_vals = sl_rcp_chunked.chunk({\"rcp\": -1}).sel(year = 2050)\n",
    "trg_vals = sl_rcp_chunked_to_interp.sel(year = 2050)\n",
    "diff = trg_vals - src_vals\n",
    "lb = diff.where(diff >= 0, np.inf)\n",
    "no_lb = np.isinf(lb).all(dim=dim)\n",
    "lb = lb.idxmin(dim).where(~no_lb, src_vals.idxmin(dim).broadcast_like(no_lb))\n",
    "ub = diff.where(diff <= 0, -np.inf)\n",
    "no_ub = np.isinf(ub).all(dim=dim)\n",
    "ub = ub.idxmax(dim).where(~no_ub, src_vals.idxmax(dim).broadcast_like(no_ub))\n",
    "assert not (no_lb & no_ub & trg_vals.notnull()).any()\n",
    "lb_val = src_vals.sel({dim: lb}, drop=True)\n",
    "ub_val = src_vals.sel({dim: ub}, drop=True)\n",
    "\n",
    "full_range = ub_val - lb_val\n",
    "assert (ub_val.where(full_range == 0, 0) == lb_val.where(full_range == 0, 0)).all()\n",
    "\n",
    "ub_wt = ((trg_vals - lb_val) / full_range).where(full_range != 0, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b0ebc8-96ce-4e2b-921e-8f6bbeddb7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sl_rcp_chunked_med = (\n",
    "    sl_rcp_med.sel(pulse_year=0, year=baselines_med.year)\n",
    "    .drop(\"pulse_year\")\n",
    "    .chunk({\"year\": 1})\n",
    ")\n",
    "sl_rcp_chunked_med_to_interp = (\n",
    "    sl_rcp_chunked_med.drop_sel(rcp=baselines_med.rcp)\n",
    "    .rename(rcp=\"tmp\")\n",
    "    .chunk({\"tmp\": 1})\n",
    ")\n",
    "sl_rcp_chunked_med = sl_rcp_chunked_med.sel(rcp=baselines_med.rcp)\n",
    "\n",
    "rcp_wt_ds_med = sl_rcp_chunked_med_to_interp.map_blocks(\n",
    "    get_bound_wts,\n",
    "    (sl_rcp_chunked_med,),\n",
    "    template=xr.Dataset(\n",
    "        {\n",
    "            \"lb\": sl_rcp_chunked_med_to_interp.astype(object),\n",
    "            \"ub\": sl_rcp_chunked_med_to_interp.astype(object),\n",
    "            \"ub_wt\": sl_rcp_chunked_med_to_interp,\n",
    "        }\n",
    "    ),\n",
    ").load()\n",
    "baseline_rcp_extra_med = (\n",
    "    rcp_wt_ds_med.ub_wt * baselines_med.load().sel(rcp=rcp_wt_ds_med.ub, drop=True)\n",
    "    + (1 - rcp_wt_ds_med.ub_wt) * baselines_med.sel(rcp=rcp_wt_ds_med.lb, drop=True)\n",
    ").rename(tmp=\"rcp\")\n",
    "baselines_med = xr.concat((baselines_med, baseline_rcp_extra_med), dim=\"rcp\").sel(\n",
    "    rcp=sl_rcp.rcp\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e86bef8f-8502-47d5-a48d-dd332b335f45",
   "metadata": {},
   "source": [
    "# Add on the post-2300 years\n",
    "By bias-correcting SESL forecasts to FACTS in 2300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7f445396-05b2-42ff-9008-29be41fa77c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "extra = sl_rcp.sel(pulse_year=0, year=slice(final_year + 1, None)).drop(\"pulse_year\")\n",
    "comp = sl_rcp.sel(pulse_year=0, year=final_year, drop=True)\n",
    "baseline_rcp = xr.concat(\n",
    "    (baseline_rcp, extra + baseline_rcp.isel(year=-1, drop=True) - comp), dim=\"year\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e2363ce7-55ce-42d9-8417-878b9d347ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add delta from SESL to baseline\n",
    "out_rcp = xr.concat(\n",
    "    (\n",
    "        baseline_rcp.expand_dims(pulse_year=[0]),\n",
    "        baseline_rcp\n",
    "        + sl_rcp.drop_sel(pulse_year=0)\n",
    "        - sl_rcp.sel(pulse_year=0, drop=True),\n",
    "    ),\n",
    "    dim=\"pulse_year\",\n",
    ")\n",
    "\n",
    "out_rcp_med = xr.concat(\n",
    "    (\n",
    "        baselines_med.expand_dims(pulse_year=[0]),\n",
    "        baselines_med\n",
    "        + sl_rcp_med.drop_sel(pulse_year=0)\n",
    "        - sl_rcp_med.sel(pulse_year=0, drop=True),\n",
    "    ),\n",
    "    dim=\"pulse_year\",\n",
    ").squeeze()\n",
    "\n",
    "out_rcp = xr.Dataset({\"gmsl\": out_rcp, \"gmsl_median\": out_rcp_med})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "420f50b3-1afb-4290-b624-d76669b83d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "del baselines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "940a9425-2de1-46a6-9d6b-246ede4b31b8",
   "metadata": {
    "tags": []
   },
   "source": [
    "## RFF-based SESL workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cae5bd6-f0b1-41fd-b170-122d7ce75f9c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fair_rff = []\n",
    "for gas_stub, version in [\n",
    "    (\"CO2_Fossil\", ps.FAIR_RFF_CO2_VERS),\n",
    "    (\"CH4\", ps.FAIR_RFF_CH4_VERS),\n",
    "    (\"N2O\", ps.FAIR_RFF_N20_VERS),\n",
    "]:\n",
    "    print(version)\n",
    "    this = xr.open_mfdataset(\n",
    "        ps.DIR_HAZARD_FAIR_RFF.glob(\n",
    "            FAIR_RFF_STUB.format(gas_stub=gas_stub, version=version)\n",
    "        ),\n",
    "        chunks={\"runid\": 5000},\n",
    "    )[[\"temperature\", \"climate_param_index\"]]\n",
    "    fair_rff.append(flatten_runtype(this.temperature))\n",
    "\n",
    "fair_rff = xr.concat(\n",
    "    fair_rff, dim=pd.Index([\"CO2_Fossil\", \"CH4\", \"N2O\"], name=\"gas\")\n",
    ").to_dataset(name=\"temperature\")\n",
    "fair_rff[\"climate_param_index\"] = this.climate_param_index.isel(pulse_year=0, drop=True)\n",
    "fair_rff = fair_rff.expand_dims({\"iter\" : [1]}).persist()\n",
    "\n",
    "# get temp projections from FAIR\n",
    "fair_temps_rff = fair_rff.temperature\n",
    "fair_params_rff = fair_rff.climate_param_index.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f72a6d4f-6b0e-4665-8c18-a2fdff79d7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "CROSSWALK = xr.open_dataset(\n",
    "'./coastal_gmsl_inputs/other/rffsp_fair_sequence.nc'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0bc9cb2-d7bc-4518-ab00-34c9edea4f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get T0 initial condition for SESL projections\n",
    "\n",
    "# Option 1: Randomly assign SESL params - Captures more of the distribution, but not\n",
    "# matched to FAIR params in same way as we did for RCP model.\n",
    "# ics_rff = get_ics(\n",
    "#     len(fair_temps_rff.simulation), params, sesl_p, ps.DIR_HAZARD_SLR_SESL_RAW\n",
    "# )\n",
    "# param_sims_rff = resample_ics(\n",
    "#     ics_rff,\n",
    "#     fair_temps_rff.simulation,\n",
    "#     params,\n",
    "# )\n",
    "\n",
    "# Option 2: Use same pairings of FAIR-SESL params as for RCP. Captures less of the SESL\n",
    "# param distribution, but maintains the random FAIR-SESL pairings from the RCP model\n",
    "\n",
    "# rff_sp, iter\n",
    "param_sims_rff = param_sims_rcp.sel(simulation=CROSSWALK.simulation, drop=True).expand_dims({'iter' : [1]})\n",
    "\n",
    "# Resample the SESL initial condition and bias correction factors to match up with the fair simulations\n",
    "fair_temps_rff = bias_correct_temps(\n",
    "    fair_temps_rff,\n",
    "    sesl_p[\"T_bias_correction_period\"],\n",
    "    param_sims_rff.T_ref,\n",
    "    first_year=2000,\n",
    ").persist()\n",
    "\n",
    "# Run sim\n",
    "sl_rff = fair_temps_rff.map_blocks(\n",
    "    project_sesl,\n",
    "    (param_sims_rff.chunk({\"runid\": 5000}),),\n",
    "    template=fair_temps_rff,\n",
    ").persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5deb7a54-0c94-49fb-b905-9cd06c14b183",
   "metadata": {},
   "outputs": [],
   "source": [
    "fair_temps_rff_diag = (\n",
    "    fair_temps_rff.sel(gas=\"CO2_Fossil\", pulse_year=[0, 2020])\n",
    "    .load()\n",
    "    .stack(simulation=[\"runid\", \"iter\"])\n",
    ")\n",
    "del fair_temps_rff, fair_rff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bea5d38-a8e6-4488-95f7-9910ea21e056",
   "metadata": {},
   "source": [
    "## Calculate weighted average of AR6 baselines for RFF-SPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404ffa3c-b15b-45cd-98a0-6daf3582a452",
   "metadata": {},
   "outputs": [],
   "source": [
    "with dask.config.set(**{\"array.slicing.split_large_chunks\": True}):\n",
    "    rff_wt_vals = (\n",
    "        sl_rff.sel(year=baseline_rcp.year, pulse_year=0, gas=\"CO2_Fossil\")\n",
    "        .drop([\"pulse_year\", \"gas\"])\n",
    "        .persist()\n",
    "    )\n",
    "rcp_wt_vals = (\n",
    "    sl_rcp.sel(year=baseline_rcp.year, pulse_year=0)\n",
    "    .drop_sel(rcp=interpolated)\n",
    "    .drop(\"pulse_year\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a032749-8fc9-4f5d-86e4-b4e1de1f4532",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rcp_wt_vals_reshaped = rcp_wt_vals.sel(simulation=fair_params_rff, drop=True).chunk(\n",
    "    rff_wt_vals.chunksizes\n",
    ")\n",
    "\n",
    "wt_ds = rff_wt_vals.map_blocks(\n",
    "    get_bound_wts,\n",
    "    (rcp_wt_vals_reshaped,),\n",
    "    template=xr.Dataset(\n",
    "        {\n",
    "            \"lb\": rff_wt_vals.astype(object),\n",
    "            \"ub\": rff_wt_vals.astype(object),\n",
    "            \"ub_wt\": rff_wt_vals,\n",
    "        }\n",
    "    ),\n",
    ").persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c5f6fb3-954c-4b53-ace8-90895bf698bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_rff = (\n",
    "    rff_wt_vals.chunk({\"year\": 10})\n",
    "    .map_blocks(\n",
    "        quantile_map_rff,\n",
    "        (\n",
    "            rcp_wt_vals.chunk({\"year\": 10}),\n",
    "            baseline_rcp.drop_sel(rcp=interpolated).chunk({\"year\": 10}),\n",
    "            wt_ds.chunk({\"year\": 10}),\n",
    "        ),\n",
    "        template=rff_wt_vals.chunk({\"year\": 10}),\n",
    "    )\n",
    "    .persist()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814495eb-cec9-451e-8a2b-341e610e9ff6",
   "metadata": {},
   "source": [
    "## Aggregate datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "977327bc-b0b8-4057-94be-fd53ffa31810",
   "metadata": {},
   "outputs": [],
   "source": [
    "with dask.config.set(**{\"array.slicing.split_large_chunks\": False}):\n",
    "    sl_rff = (\n",
    "        sl_rff.sel(year=baseline_rff.year)\n",
    "        .chunk({k: v for k, v in baseline_rff.chunksizes.items() if k in sl_rff.dims})\n",
    "        .persist()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86410365-51c1-4fcd-bf87-a125a2ce86bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_rff = xr.concat(\n",
    "    (\n",
    "        baseline_rff.expand_dims(pulse_year=[0]),\n",
    "        baseline_rff\n",
    "        + sl_rff.drop_sel(pulse_year=0)\n",
    "        - sl_rff.sel(pulse_year=0, drop=True),\n",
    "    ),\n",
    "    dim=\"pulse_year\",\n",
    ").persist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ac5961-5d54-4542-9bb5-8bbde0cad2c4",
   "metadata": {},
   "source": [
    "## Diagnostics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86db0020-e0e7-4b20-9e23-98357d154c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_rff_diag = (\n",
    "    out_rff.sel(pulse_year=[0, 2020], gas=\"CO2\")\n",
    "    .load()\n",
    "    .stack(simulation=[\"rff_sp\", \"iter\"])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6384babd-7e0d-4895-b90f-75445ab29a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "DIAG_YEARS = [2100, 2150, 2300]\n",
    "\n",
    "diag = {}\n",
    "for key, out, temp in [\n",
    "    (\"rcp\", out_rcp.gmsl, fair_temps_rcp),\n",
    "    (\n",
    "        \"rff\",\n",
    "        out_rff_diag,\n",
    "        fair_temps_rff_diag,\n",
    "    ),\n",
    "]:\n",
    "    quantiles = [0.01, 0.05, 0.17, 0.5, 0.83, 0.95, 0.99]\n",
    "    sl_diff = out.sel(pulse_year=2020, drop=True) - out.sel(pulse_year=0, drop=True)\n",
    "    t_diff = temp.sel(pulse_year=2020, drop=True) - temp.sel(pulse_year=0, drop=True)\n",
    "    rat = sl_diff / t_diff.reindex(year=sl_diff.year)\n",
    "    gmsl_pulse_qs = sl_diff.sel(year=DIAG_YEARS).quantile(q=quantiles, dim=\"simulation\")\n",
    "    gmst_pulse_qs = t_diff.sel(year=DIAG_YEARS).quantile(q=quantiles, dim=\"simulation\")\n",
    "    rat_qs = rat.sel(year=DIAG_YEARS).quantile(q=quantiles, dim=\"simulation\")\n",
    "    gmsl_base_qs = out.sel(pulse_year=0, year=DIAG_YEARS).quantile(\n",
    "        q=quantiles, dim=\"simulation\"\n",
    "    )\n",
    "    diag[key] = {\n",
    "        \"gmsl_pulse_qs\": gmsl_pulse_qs,\n",
    "        \"gmst_pulse_qs\": gmst_pulse_qs,\n",
    "        \"rat_qs\": rat_qs,\n",
    "        \"gmsl_base_qs\": gmsl_base_qs,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2257426b-77ea-4a58-9343-f5bc9c2f3feb",
   "metadata": {},
   "source": [
    "### $\\Delta$ GMSL from Pulse (cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7290009e-3315-4232-8dcd-62d97a060d30",
   "metadata": {},
   "source": [
    "#### 2100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea08005c-9102-40f8-9846-59e9ee357b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "diag[\"rcp\"][\"gmsl_pulse_qs\"].sel(year=2100).to_series().unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74db084d-84ab-4495-a14d-778c242a41c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "diag[\"rff\"][\"gmsl_pulse_qs\"].sel(year=2100).to_series()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e5f118-d66d-4267-b6e7-a8ba6b5f130d",
   "metadata": {},
   "source": [
    "#### 2150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64909200-627f-4c27-8ed6-76984742d4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "diag[\"rcp\"][\"gmsl_pulse_qs\"].sel(year=2150).to_series().unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64995a76-91d2-4e14-bb25-9dbf4164e687",
   "metadata": {},
   "outputs": [],
   "source": [
    "diag[\"rff\"][\"gmsl_pulse_qs\"].sel(year=2150).to_series()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ef4517-4391-40f8-b45d-89a96418880c",
   "metadata": {},
   "source": [
    "#### 2300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc55911-a71a-46e5-9bea-89975d425dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "diag[\"rcp\"][\"gmsl_pulse_qs\"].sel(year=2300).to_series().unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5c111f-29cd-4e99-8610-cfcc8a2fa70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "diag[\"rff\"][\"gmsl_pulse_qs\"].sel(year=2300).to_series()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e92e8f6e-60ea-4abe-bcd8-59aaeebf5059",
   "metadata": {},
   "source": [
    "### $\\Delta$ GMST from Pulse ($^{\\circ}C$)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5cd918e-44e1-48d5-8093-a6f75e7f4f84",
   "metadata": {},
   "source": [
    "#### 2100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27778ea-b7d1-430c-8f96-7d6f8fedfccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "diag[\"rcp\"][\"gmst_pulse_qs\"].sel(year=2100).to_series().unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4f0185-8023-4351-8227-3c9019976a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "diag[\"rff\"][\"gmst_pulse_qs\"].sel(year=2100).to_series()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "291a9c67-927c-4d0d-8687-d276685ee7f5",
   "metadata": {},
   "source": [
    "#### 2150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50120028-e3b2-4887-b912-705a32dd01d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "diag[\"rcp\"][\"gmst_pulse_qs\"].sel(year=2150).to_series().unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09b25cd-d684-4ed0-a44a-a8341b562df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "diag[\"rff\"][\"gmst_pulse_qs\"].sel(year=2150).to_series()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a216573-e215-43d1-9a64-fb2519720a55",
   "metadata": {},
   "source": [
    "#### 2300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eac0ce5-a6ab-4f41-bab4-84aa547a4823",
   "metadata": {},
   "outputs": [],
   "source": [
    "diag[\"rcp\"][\"gmst_pulse_qs\"].sel(year=2300).to_series().unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e733f2b-e4c9-409e-9069-b142eee7228f",
   "metadata": {},
   "outputs": [],
   "source": [
    "diag[\"rff\"][\"gmst_pulse_qs\"].sel(year=2300).to_series()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c830d574-91c6-474b-a6af-99ed976a1b16",
   "metadata": {},
   "source": [
    "### $\\Delta$ GMSL / $\\Delta$ GMST ($\\frac{cm}{^{\\circ}C}$)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d44c5626-e8bc-4c0c-89d1-495251355f3e",
   "metadata": {},
   "source": [
    "#### 2100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f71abb9-ec00-4a0b-988d-ead7dfd628d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "diag[\"rcp\"][\"rat_qs\"].sel(year=2100).to_series().unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6e53b2-6cc6-4b0e-a6b1-0acf5a6c006d",
   "metadata": {},
   "outputs": [],
   "source": [
    "diag[\"rff\"][\"rat_qs\"].sel(year=2100).to_series()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c66d9f91-3b93-4e34-8d29-7d24eea28e14",
   "metadata": {},
   "source": [
    "#### 2150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0acd930b-d8dd-45aa-9a4a-6e6663e24297",
   "metadata": {},
   "outputs": [],
   "source": [
    "diag[\"rcp\"][\"rat_qs\"].sel(year=2150).to_series().unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c982a9-08ae-4452-8ca7-121776eb3e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "diag[\"rff\"][\"rat_qs\"].sel(year=2150).to_series()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b8d8988-c1b6-46af-9345-946b1e8e43f7",
   "metadata": {},
   "source": [
    "#### 2300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d27e435-e7de-4e68-a7fe-5c1dc76cd20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "diag[\"rcp\"][\"rat_qs\"].sel(year=2300).to_series().unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82fd48f3-1d7a-4521-82ac-9ecf61d3b3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "diag[\"rff\"][\"rat_qs\"].sel(year=2300).to_series()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d0f18f-0602-43e5-9402-e843b67feafd",
   "metadata": {},
   "source": [
    "### Baseline GMSL, rel. 1991-2009 (cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b500f8d-5f43-4bd0-942b-df79a0b80d14",
   "metadata": {},
   "source": [
    "#### 2100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f47216e-be39-431f-863f-bc8111923e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "diag[\"rcp\"][\"gmsl_base_qs\"].sel(year=2100).to_series().unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7ade6d-8580-4f2d-8389-8fa6189149eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "diag[\"rff\"][\"gmsl_base_qs\"].sel(year=2100).to_series()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8670df48-a662-44e1-9bac-b36866ffe58d",
   "metadata": {},
   "source": [
    "#### 2150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448b053e-5e52-4f77-8c36-b515aa42a523",
   "metadata": {},
   "outputs": [],
   "source": [
    "diag[\"rcp\"][\"gmsl_base_qs\"].sel(year=2150).to_series().unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086a8aa4-67e2-48ea-9280-e77d8c2a57f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "diag[\"rff\"][\"gmsl_base_qs\"].sel(year=2150).to_series()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29bf1ad9-5f20-45bb-bf35-8e4764f8e957",
   "metadata": {},
   "source": [
    "#### 2300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ca18a7-701c-4a54-ac3a-3a9131ba5a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "diag[\"rcp\"][\"gmsl_base_qs\"].sel(year=2300).to_series().unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af089cc9-9e13-4929-afb0-b6511952c541",
   "metadata": {},
   "outputs": [],
   "source": [
    "diag[\"rff\"][\"gmsl_base_qs\"].sel(year=2300).to_series()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "283e9a5f-d473-4c93-a021-c532929853ea",
   "metadata": {},
   "source": [
    "## Reshape to add back runtype dim and crop years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e084670-11d2-4684-8fde-d98496a5a61f",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_rcp = unflatten_runtype(out_rcp.sel(year=slice(None, 2300)))\n",
    "out_rff = unflatten_runtype(out_rff.sel(year=slice(None, 2300))).persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ebe0b7-8742-4a09-a5df-2cb43b42b12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_rcp = out_rcp.chunk(\n",
    "    {k: v for k, v in out_rff.chunksizes.items() if k in out_rcp.dims}\n",
    ").persist()\n",
    "\n",
    "out_rff = (\n",
    "    out_rff.to_dataset(name=\"gmsl\")\n",
    "    .rename(iter=\"simulation\")\n",
    "    .chunk({\"year\": 100})\n",
    "    .persist()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da126f90-40dc-4c41-97f0-952e9a695d92",
   "metadata": {},
   "source": [
    "## Add attrs and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7001895d-cb4c-4e00-8025-9a0f3500087e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b8575d1-e1a8-4a89-826b-5411e546dbed",
   "metadata": {},
   "outputs": [],
   "source": [
    "REF_PERIOD = \"1991-2009\"\n",
    "\n",
    "attr_all = {\n",
    "    \"units\": \"cm\",\n",
    "    \"updated\": pd.Timestamp.now(tz=\"US/Pacific\").strftime(\"%c\"),\n",
    "    \"reference_period\": \"1991-2009\",\n",
    "    \"history\": HISTORY,\n",
    "    \"author\": AUTHOR,\n",
    "    \"contact\": CONTACT,\n",
    "}\n",
    "\n",
    "out_rcp.attrs.update(\n",
    "    {\n",
    "        **attr_all,\n",
    "        \"description\": DESCRIPTION_RCP,\n",
    "        \"method\": METHOD_RCP,\n",
    "        \"version\": ps.FAIR_RCP_VERS,\n",
    "    }\n",
    ")\n",
    "\n",
    "out_rff.attrs.update(\n",
    "    {\n",
    "        **attr_all,\n",
    "        \"description\": DESCRIPTION_RFF,\n",
    "        \"method\": METHOD_RFF,\n",
    "        \"version\": ps.FAIR_RFF_OUT_VERS,\n",
    "    }\n",
    ")\n",
    "\n",
    "for ds in [out_rcp, out_rff]:\n",
    "    ds.gmsl.attrs.update(\n",
    "        {\n",
    "            \"description\": \"Simulations of 19-year centered mean of Global Mean Sea Level anomaly under SSP scenarios\",\n",
    "            \"units\": \"cm\",\n",
    "            \"reference_period\": REF_PERIOD,\n",
    "            \"long_name\": \"GMSL sims rel. \" + REF_PERIOD,\n",
    "        }\n",
    "    )\n",
    "    ds.pulse_year.attrs.update({\"description\": \"Year of GHG pulse\"})\n",
    "\n",
    "out_rcp.gmsl_median.attrs.update(\n",
    "    {\n",
    "        \"description\": \"Simulation of 19-year centered mean of Global Mean Sea Level anomaly under SSP scenarios, using median SESL and FAIR parameters\",\n",
    "        \"units\": \"cm\",\n",
    "        \"reference_period\": REF_PERIOD,\n",
    "        \"long_name\": \"GMSL med. rel. 1991-2009\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0cedc3-72e9-4a5a-8ef0-ab9b0aa66393",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_rcp.to_zarr(ps.PATH_HAZARD_SLR_GMSL_FAIR_RCP, mode=\"w\")\n",
    "# out_rff.to_zarr(ps.PATH_HAZARD_SLR_GMSL_FAIR_RFF, mode=\"w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "187f8170-447a-4182-8ad5-dffdc862436b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.close(), client.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "1c563e5d4a5be05aba28b7900c492566e739e975fb2c44970ba8f8dd17836f0d"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "05092888f2db427da3b07cf0ce342add": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_e9a1675ab93a48b6a79a062da4eeab25",
       "style": "IPY_MODEL_6e4bc07a5bd5496eb0986f56d308b633",
       "value": "\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table style=\"text-align: right;\">\n    <tr><th>Workers</th> <td>98</td></tr>\n    <tr><th>Cores</th> <td>98</td></tr>\n    <tr><th>Memory</th> <td>637.00 GiB</td></tr>\n</table>\n</div>\n"
      }
     },
     "1667c5339013430da6dc54a633f4e9a2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ButtonModel",
      "state": {
       "description": "Adapt",
       "layout": "IPY_MODEL_4c2c162631eb4ba291751e07c8107644",
       "style": "IPY_MODEL_3019b8f481b446b8a052559555bf1c5c"
      }
     },
     "1c3a0190071841ecb21959fdadd41fcf": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_fc18d7c530794c3384fbe66f6ee34efa",
        "IPY_MODEL_5886df40119945298d2f1f5d2d0dc9a0"
       ],
       "layout": "IPY_MODEL_77c26d5df20441819e1ccaeb6150444c"
      }
     },
     "1cdcf02ccc77421c831c0200d4c9a831": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_71bcca12bc594f928ebbf132213228ab",
       "style": "IPY_MODEL_54552e853624425f986b2d029f25ca77",
       "value": "<p><b>Dashboard: </b><a href=\"/services/dask-gateway/clusters/daskhub-dev.1021fa4eaa424a28b6c9eaa74eb2df9a/status\" target=\"_blank\">/services/dask-gateway/clusters/daskhub-dev.1021fa4eaa424a28b6c9eaa74eb2df9a/status</a></p>\n"
      }
     },
     "20606d37dbb24282b95c2ce0b57991fe": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_86dd5802281d44a6976ad1e90f3d91e4",
        "IPY_MODEL_23d8ca46fbc3400daf0deaba35f74b72",
        "IPY_MODEL_1667c5339013430da6dc54a633f4e9a2"
       ],
       "layout": "IPY_MODEL_aa1656bf4f76445aa8ce978265331484"
      }
     },
     "23d8ca46fbc3400daf0deaba35f74b72": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "IntTextModel",
      "state": {
       "description": "Maximum",
       "layout": "IPY_MODEL_4c2c162631eb4ba291751e07c8107644",
       "step": 1,
       "style": "IPY_MODEL_3e1c6308705940a09166323d8893a441"
      }
     },
     "2b2f18f614fc434e836dd998d4499d5a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "3019b8f481b446b8a052559555bf1c5c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ButtonStyleModel",
      "state": {}
     },
     "3e1c6308705940a09166323d8893a441": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "41b1ec216806411697d5b95d1ca2b133": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "4c2c162631eb4ba291751e07c8107644": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "width": "150px"
      }
     },
     "53c66727235a4f0592555db7cf430109": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_d7c18c57112742488998884f04947a3f",
       "style": "IPY_MODEL_41b1ec216806411697d5b95d1ca2b133",
       "value": "<h2>GatewayCluster</h2>"
      }
     },
     "54552e853624425f986b2d029f25ca77": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "5886df40119945298d2f1f5d2d0dc9a0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ButtonModel",
      "state": {
       "description": "Scale",
       "layout": "IPY_MODEL_4c2c162631eb4ba291751e07c8107644",
       "style": "IPY_MODEL_9c63b9d0d1c04ddd9def51659f9daccb"
      }
     },
     "59eceb20b2fb42b1be760870230687e2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "6086b3107a3c4f858e72f3632b34d637": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "6c0dd8fb4842413c9e242a9e2f721697": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "6e4bc07a5bd5496eb0986f56d308b633": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "71bcca12bc594f928ebbf132213228ab": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "77c26d5df20441819e1ccaeb6150444c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "85d8db4bc7334e1ab010b5694737c1f8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "VBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_53c66727235a4f0592555db7cf430109",
        "IPY_MODEL_acae39c8c9d947b2af9f024baee17220",
        "IPY_MODEL_d4041a71d9134349bd4314c98fb704f3",
        "IPY_MODEL_1cdcf02ccc77421c831c0200d4c9a831"
       ],
       "layout": "IPY_MODEL_891f1bf0eb7049a7965a24ace92f07e6"
      }
     },
     "86dd5802281d44a6976ad1e90f3d91e4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "IntTextModel",
      "state": {
       "description": "Minimum",
       "layout": "IPY_MODEL_4c2c162631eb4ba291751e07c8107644",
       "step": 1,
       "style": "IPY_MODEL_6c0dd8fb4842413c9e242a9e2f721697"
      }
     },
     "891f1bf0eb7049a7965a24ace92f07e6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "9c63b9d0d1c04ddd9def51659f9daccb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ButtonStyleModel",
      "state": {}
     },
     "aa1656bf4f76445aa8ce978265331484": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "acae39c8c9d947b2af9f024baee17220": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_05092888f2db427da3b07cf0ce342add",
        "IPY_MODEL_c88b982089bb4673ad9b4da4e11ec1b8"
       ],
       "layout": "IPY_MODEL_6086b3107a3c4f858e72f3632b34d637"
      }
     },
     "c88b982089bb4673ad9b4da4e11ec1b8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "AccordionModel",
      "state": {
       "_titles": {
        "0": "Manual Scaling",
        "1": "Adaptive Scaling"
       },
       "children": [
        "IPY_MODEL_1c3a0190071841ecb21959fdadd41fcf",
        "IPY_MODEL_20606d37dbb24282b95c2ce0b57991fe"
       ],
       "layout": "IPY_MODEL_e6ec89ec57524b388e0118be87b8872d",
       "selected_index": null
      }
     },
     "d4041a71d9134349bd4314c98fb704f3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_59eceb20b2fb42b1be760870230687e2",
       "style": "IPY_MODEL_d590c74cecf841d68c4d287297e33494",
       "value": "<p><b>Name: </b>daskhub-dev.1021fa4eaa424a28b6c9eaa74eb2df9a</p>"
      }
     },
     "d590c74cecf841d68c4d287297e33494": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "d7c18c57112742488998884f04947a3f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "e6ec89ec57524b388e0118be87b8872d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "min_width": "500px"
      }
     },
     "e9a1675ab93a48b6a79a062da4eeab25": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "min_width": "150px"
      }
     },
     "fc18d7c530794c3384fbe66f6ee34efa": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "IntTextModel",
      "state": {
       "description": "Workers",
       "layout": "IPY_MODEL_4c2c162631eb4ba291751e07c8107644",
       "step": 1,
       "style": "IPY_MODEL_2b2f18f614fc434e836dd998d4499d5a"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
